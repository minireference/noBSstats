
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Chapter 3: Inferential statistics &#8212; No Bullshit Guide to Statistics</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'stats_overview/03_STATS';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="No Bullshit Guide to Statistics - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="No Bullshit Guide to Statistics - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    No Bullshit Guide to Statistics
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks/10_DATA.html">Chapter 1 — Data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/11_intro_to_data.html">Section 1.1 — Introduction to data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/12_data_in_practice.html">Section 1.2 — Data in practice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/13_descriptive_statistics.html">Section 1.3 — Descriptive statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/exercises_13_descr_stats.html">Descriptive statistics exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks/20_PROB.html">Chapter 2 — Probability theory</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/21_discrete_random_vars.html">Section 2.1 — Discrete random variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/22_multiple_random_vars.html">Section 2.2 — Multiple random variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/23_inventory_discrete_dists.html">Section 2.3 — Inventory of discrete distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/24_continuous_random_vars.html">Section 2.4 — Continuous random variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/25_multiple_continuous_random_vars.html">Section 2.5 — Multiple continuous random variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/26_inventory_continuous_dists.html">Section 2.6 — Inventory of continuous distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/27_simulations.html">Section 2.7 — Simulation and empirical distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/28_random_samples.html">Section 2.8 — Probability models for random samples</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks/30_STATS.html">Chapter 3 — Classical statistics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/31_estimators.html">Section 3.1 — Estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/exercises_31_estimtors.html">Exercises for Section 3.1 Estimates and estimators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/32_confidence_intervals.html">Section 3.2 — Confidence intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../exercises/exercises_32_confidence_intervals.html">Exercises for Section 3.2 Confidence intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/33_intro_to_NHST.html">Section 3.3 — Introduction to hypothesis testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/34_analytical_approx.html">Section 3.4 — Hypothesis testing using analytical approximations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/35_two_sample_tests.html">Section 3.5 — Two-sample hypothesis tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/36_design.html">Section 3.6 — Statistical design and error analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/37_inventory_stats_tests.html">Section 3.7 — Inventory of statistical tests</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../examples/README.html">Statistical analysis examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../examples/statistical_design.html">Statistical design examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/one_sample_z-test.html">One-sample z-test for the mean</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/one_sample_t-test.html">One-sample t-test for the mean</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/two_sample_t-test.html">Welch’s two-sample <span class="math notranslate nohighlight">\(t\)</span>-test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/ANOVA.html">Analysis of variance (ANOVA)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../examples/two_sample_equivalence_test.html">Two-sample equivalence test</a></li>

</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks/40_LINEAR_MODELS.html">Chapter 4 — Linear models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/41_simple_linear_regression.html">Section 4.1 — Simple linear regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/42_multiple_linear_regression.html">Section 4.2 — Multiple linear regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/43_interpreting_linear_models.html">Section 4.3 — Interpreting linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/44_regression_with_categorical_predictors.html">Section 4.4 — Regression with categorical predictors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/45_causal_inference.html">Section 4.5 — Model selection for causal inference</a></li>

<li class="toctree-l2"><a class="reference internal" href="../notebooks/46_generalized_linear_models.html">Section 4.6 — Generalized linear models</a></li>

</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks/50_BAYESIAN_STATS.html">Chapter 5 — Bayesian statistics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/51_intro_to_Bayesian_stats.html">Section 5.1 — Introduction to Bayesian statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/52_Bayesian_inference_computations.html">Section 5.2 — Bayesian inference computations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/53_Bayesian_linear_models.html">Section 5.3 — Bayesian linear models</a></li>

<li class="toctree-l2"><a class="reference internal" href="../notebooks/54_difference_between_means.html">Section 5.4 — Bayesian difference between means</a></li>

<li class="toctree-l2"><a class="reference internal" href="../notebooks/55_hierarchical_models.html">Section 5.5 — Hierarchical models</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials/appendix.html">Appendix</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/python_tutorial.html">Appendix C — Python tutorial</a></li>












<li class="toctree-l2"><a class="reference internal" href="../tutorials/pandas_tutorial.html">Appendix D — Pandas tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/seaborn_tutorial.html">Appendix E — Seaborn tutorial</a></li>

<li class="toctree-l2"><a class="reference internal" href="../tutorials/calculus_tutorial.html">Appendix F — Calculus tutorial</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../reading_group/info.html">noBSstats Reading Group</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../blogposts/index.html">Blog posts</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../blogposts/python_for_stats.html">Using Python for learning statistics Part 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blogposts/probability_models.html">Using Python for probability calculations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blogposts/sampling_distributions.html">Sampling distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blogposts/bootstrap.html">Bootstrap estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blogposts/simulation_hypothesis_tests.html">Hypothesis testing using simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blogposts/permutation_test.html">Permutation tests for comparing two groups</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blogposts/stats_procedures.html">Python libraries for doing statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../blogposts/python_stats_libraries.html">Python libraries for doing statistics</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/minireference/noBSstats/main?urlpath=lab/tree/./stats_overview/03_STATS.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/minireference/noBSstats" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/minireference/noBSstats/issues/new?title=Issue%20on%20page%20%2Fstats_overview/03_STATS.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/stats_overview/03_STATS.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 3: Inferential statistics</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#notebook-setup">Notebook setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimators">Estimators</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definitions">Definitions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#difference-between-group-means">Difference between group means</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#particular-value-of-the-estimator-dmeans">Particular value of the estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-distribution-of-the-estimator-dmeans">Sampling distribution of the estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-sampling-distribution-of-dmeans">Plot the sampling distribution of <code class="docutils literal notranslate"><span class="pre">dmeans</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#theoretical-model-for-the-sampling-distribution-of-dmeans">Theoretical model for the sampling distribution of <code class="docutils literal notranslate"><span class="pre">dmeans</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regroup-and-reality-check">Regroup and reality check</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#why-are-we-doing-all-this-modelling">Why are we doing all this modelling?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hypothesis-testing">Hypothesis testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview-of-the-hypothesis-testing-procedure">Overview of the hypothesis testing procedure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-the-result-of-a-hypothesis-test-optional">Interpreting the result of a hypothesis test (optional)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#start-by-loading-the-data-again">Start by loading the data again…</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-1-permutation-test-for-comparing-two-groups">Approach 1: Permutation test for comparing two groups</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#running-a-permutation-test">Running a permutation test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#permutations-test-using-scipy">Permutations test using SciPy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-2-analytical-approximations-for-hypothesis-testing">Approach 2: Analytical approximations for hypothesis testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#student-s-t-test-pooled-variance">Student’s t-test (pooled variance)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#black-box-approach">Black-box approach</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#student-s-t-test-under-the-hood">Student’s t-test under the hood</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#welch-s-t-test-unpooled-variances">Welch’s t-test (unpooled variances)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-question-1">Summary of Question 1</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-the-effect-size">Estimating the effect size</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-1-confidence-intervals-using-bootstrap-estimation">Approach 1: Confidence intervals using bootstrap estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#scipy-bootstrap-method">SciPy bootstrap method</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-2-confidence-intervals-using-analytical-approximations">Approach 2: Confidence intervals using analytical approximations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pooled-variance">Using pooled variance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#using-unpooled-variance">Using unpooled variance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-question-2-results">Summary of Question 2 results</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#standardized-effect-size-optional">Standardized effect size (optional)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-of-amy-s-statistical-analysis">Conclusion of Amy’s statistical analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-statistics-for-convincing-others">Using statistics for convincing others</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-of-resampling-methods-and-analytical-approximations">Comparison of resampling methods and analytical approximations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-statistics-topics-in-the-book">Other statistics topics in the book</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-3-inferential-statistics">
<h1>Chapter 3: Inferential statistics<a class="headerlink" href="#chapter-3-inferential-statistics" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="https://docs.google.com/document/d/1fwep23-95U-w1QMPU31nOvUnUXE2X3s_Dbk5JuLlKAY/edit#heading=h.chm9v0ef9ilf">Link to book outline</a></p>
<p>See video explanations here:<br />
<a class="reference external" href="https://www.youtube.com/watch?v=DwjWJcA2Qss&amp;amp;list=PLGmu4KtWiH680gMQnSbSADBuLnoyBUVFg&amp;amp;index=3"><img alt="" src="https://img.youtube.com/vi/DwjWJcA2Qss/mqdefault.jpg" /></a></p>
<p>Concept map:<br />
<img alt="concepts_STATS.png" src="../_images/concepts_STATS.png" /></p>
<section id="notebook-setup">
<h2>Notebook setup<a class="headerlink" href="#notebook-setup" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># loading Python modules</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>

<span class="c1"># set random seed for repeatability</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># notebooks figs setup</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format=&#39;retina&#39;
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">:(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">)})</span>
<span class="n">blue</span><span class="p">,</span> <span class="n">orange</span>  <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Main idea = learn about a population based on a sample</p></li>
<li><p>Recall Amy’s two research questions about the employee lifetime value (ELV) data:</p>
<ul>
<li><p>Question 1 = Is there a difference between ELV of the two groups? → <strong>hypothesis testing</strong></p></li>
<li><p>Question 2 = How much difference in ELV does stats training provide? → <strong>estimation</strong></p></li>
</ul>
</li>
<li><p>Inferential statistics provides us with tools to answer both of these questions</p></li>
</ul>
</section>
<section id="estimators">
<h2>Estimators<a class="headerlink" href="#estimators" title="Link to this heading">#</a></h2>
<p>We’ll begin our study of inferential statistics by introducing <strong>estimators</strong>,
which are the math tools used for both <strong>estimation</strong>  and <strong>hypothesis testing</strong>.</p>
<p><img alt="simplified_estimators.png" src="../_images/simplified_estimators.png" /></p>
<p><span class="math notranslate nohighlight">\(\def\stderr#1{\mathbf{se}_{#1}}\)</span>
<span class="math notranslate nohighlight">\(\def\stderrhat#1{\hat{\mathbf{se}}_{#1}}\)</span></p>
<section id="definitions">
<h3>Definitions<a class="headerlink" href="#definitions" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>We use the term “estimator” to describe a function <span class="math notranslate nohighlight">\(g\)</span> that takes samples as inputs
and produces parameter estimates as outputs.
Written mathematically, and estimator is a function of the form:
$<span class="math notranslate nohighlight">\(
 g \colon \underbrace{\mathcal{X}\times \mathcal{X}\times \cdots \times \mathcal{X}}_{n \textrm{ copies}}
 \quad \to \quad \mathbb{R},
\)</span><span class="math notranslate nohighlight">\(
where \)</span>n<span class="math notranslate nohighlight">\( is the samples size and \)</span>\mathcal{X}<span class="math notranslate nohighlight">\( denotes the possible values of the random variable \)</span>X$.</p></li>
<li><p>We give different names to estimates, depending on the use case:</p>
<ul>
<li><p><strong>statistic</strong> = a quantity computed from a sample (e.g. descriptive statistics)</p></li>
<li><p><strong>parameter estimates</strong> = statistics that estimate population parameters</p></li>
<li><p><strong>test statistic</strong> = an estimate used as part of hypothesis testing procedure</p></li>
</ul>
</li>
<li><p>The <strong>value</strong> of the estimator <span class="math notranslate nohighlight">\(g(\mathbf{x})\)</span> is computed from a particular sample
<span class="math notranslate nohighlight">\(\mathbf{x} = (x_1, x_2, \ldots, x_n)\)</span>.</p></li>
<li><p>The <strong>sampling distribution</strong> of the estimator <span class="math notranslate nohighlight">\(g\)</span> is the distribution of <span class="math notranslate nohighlight">\(g(\mathbf{X})\)</span>,
where <span class="math notranslate nohighlight">\(\mathbf{X} = (X_1, X_2, \ldots, X_n)\)</span> is a <em>random sample</em>.</p></li>
<li><p>Example of estimators you’re already familiar with (discussed in descriptive statistics):</p>
<ul>
<li><p>Sample mean</p>
<ul>
<li><p>estimator: <span class="math notranslate nohighlight">\(\overline{\mathbf{x}} = g(\mathbf{x}) = \frac{1}{n}\sum_{i=1}^n x_i\)</span></p></li>
<li><p>gives an estimate for the population mean <span class="math notranslate nohighlight">\(\mu\)</span></p></li>
<li><p>sampling distribution: <span class="math notranslate nohighlight">\(\overline{\mathbf{X}} = g(\mathbf{X}) = \frac{1}{n}\sum_{i=1}^n X_i\)</span></p></li>
</ul>
</li>
<li><p>Sample variance</p>
<ul>
<li><p>estimator: <span class="math notranslate nohighlight">\(s_{\mathbf{x}}^2 = h(\mathbf{x}) = \frac{1}{n-1}\sum_{i=1}^n (x_i-\overline{\mathbf{x}})^2\)</span></p></li>
<li><p>gives an estimate for the population variance <span class="math notranslate nohighlight">\(\sigma^2\)</span></p></li>
<li><p>sampling distribution: <span class="math notranslate nohighlight">\(S_{\mathbf{X}}^2 = h(\mathbf{X}) = \frac{1}{n-1}\sum_{i=1}^n (X_i-\overline{\mathbf{X}})^2\)</span></p></li>
</ul>
</li>
</ul>
</li>
<li><p>In this notebook we focus on one estimator: <strong>difference between group means</strong></p>
<ul>
<li><p>estimator: <span class="math notranslate nohighlight">\(d = \texttt{mean}(\mathbf{x}_A) - \texttt{mean}(\mathbf{x}_{B}) = \overline{\mathbf{x}}_{A} - \overline{\mathbf{x}}_{B}\)</span></p></li>
<li><p>gives an estimate for the difference between population means: <span class="math notranslate nohighlight">\(\Delta =  \mu_A - \mu_{B}\)</span></p></li>
<li><p>sampling distribution: <span class="math notranslate nohighlight">\(D = \overline{\mathbf{X}}_A - \overline{\mathbf{X}}_{B}\)</span>, which is a random variable</p></li>
</ul>
</li>
</ul>
<!-- CONVENTION: 
     In the book we'll use \hat{d} and \hat{D},
     but in this notebook we'll keep the d and D to avoid changing notation --></section>
<section id="difference-between-group-means">
<h3>Difference between group means<a class="headerlink" href="#difference-between-group-means" title="Link to this heading">#</a></h3>
<p>Consider two normally distributed random variables <span class="math notranslate nohighlight">\(X_A\)</span> and <span class="math notranslate nohighlight">\(X_B\)</span>:
$<span class="math notranslate nohighlight">\( 
X_A \sim \mathcal{N}\!\left(\mu_A, \sigma_A \right)
\qquad
\textrm{and}
\qquad
X_B \sim \mathcal{N}\!\left(\mu_B, \sigma_B \right)
\)</span>$
that describe the probability distribution for groups A and B, respectively.</p>
<ul class="simple">
<li><p>A sample of size <span class="math notranslate nohighlight">\(n_A\)</span> from <span class="math notranslate nohighlight">\(X_A\)</span> is denoted <span class="math notranslate nohighlight">\(\mathbf{x}_A = (x_1, x_2, \ldots, x_{n_A})\)</span>=<code class="docutils literal notranslate"><span class="pre">xA</span></code>,
and let <span class="math notranslate nohighlight">\(\mathbf{x}_B = (x_1, x_2, \ldots, x_{n_B})\)</span>=<code class="docutils literal notranslate"><span class="pre">xB</span></code> be a random sample of size <span class="math notranslate nohighlight">\(n_B\)</span> from <span class="math notranslate nohighlight">\(X_B\)</span>.</p></li>
<li><p>We compute the mean in each group: <span class="math notranslate nohighlight">\(\overline{\mathbf{x}}_{A} = \texttt{mean}(\mathbf{x}_A)\)</span>
and <span class="math notranslate nohighlight">\(\overline{\mathbf{x}}_{B} = \texttt{mean}(\mathbf{x}_B)\)</span></p></li>
<li><p>The value of the estimator is <span class="math notranslate nohighlight">\(d = \overline{\mathbf{x}}_{A} - \overline{\mathbf{x}}_{B}\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">dmeans</span><span class="p">(</span><span class="n">xA</span><span class="p">,</span> <span class="n">xB</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Estimator for the difference between group means.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xA</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xB</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span>
</pre></div>
</div>
</div>
</div>
<p>Note the difference between group means is precisely the estimator Amy need for her analysis (<strong>Group S</strong> and <strong>Group NS</strong>). We intentionally use the labels <strong>A</strong> and <strong>B</strong> to illustrate the general case.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># example parameters for each group</span>
<span class="n">muA</span><span class="p">,</span> <span class="n">sigmaA</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">muB</span><span class="p">,</span> <span class="n">sigmaB</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">20</span>

<span class="c1"># size of samples for each group</span>
<span class="n">nA</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">nB</span> <span class="o">=</span> <span class="mi">4</span>
</pre></div>
</div>
</div>
</div>
<section id="particular-value-of-the-estimator-dmeans">
<h4>Particular value of the estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code><a class="headerlink" href="#particular-value-of-the-estimator-dmeans" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xA</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">muA</span><span class="p">,</span> <span class="n">sigmaA</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nA</span><span class="p">)</span>  <span class="c1"># random sample from Group A</span>
<span class="n">xB</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">muB</span><span class="p">,</span> <span class="n">sigmaB</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nB</span><span class="p">)</span>  <span class="c1"># random sample from Group B</span>

<span class="n">d</span> <span class="o">=</span> <span class="n">dmeans</span><span class="p">(</span><span class="n">xA</span><span class="p">,</span> <span class="n">xB</span><span class="p">)</span>
<span class="n">d</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(96.37484873437)
</pre></div>
</div>
</div>
</div>
<p>The value of <span class="math notranslate nohighlight">\(d\)</span> computed from the samples is an estimate for the difference between means of two groups: <span class="math notranslate nohighlight">\(\Delta =  \mu_A - \mu_{B}\)</span> (which we know is <span class="math notranslate nohighlight">\(100\)</span> in this example).</p>
</section>
<section id="sampling-distribution-of-the-estimator-dmeans">
<h4>Sampling distribution of the estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code><a class="headerlink" href="#sampling-distribution-of-the-estimator-dmeans" title="Link to this heading">#</a></h4>
<p>How well does the estimate <span class="math notranslate nohighlight">\(d\)</span> approximate the true value <span class="math notranslate nohighlight">\(\Delta\)</span>?
<strong>What is the accuracy and variability of the estimates we can expect?</strong></p>
<p>To answer these questions, consider the random samples
<span class="math notranslate nohighlight">\(\mathbf{X}_A = (X_1, X_2, \ldots, X_{n_A})\)</span>
and <span class="math notranslate nohighlight">\(\mathbf{X}_B = (X_1, X_2, \ldots, X_{n_B})\)</span>,
then compute the <strong>sampling distribution</strong>: <span class="math notranslate nohighlight">\(D = \overline{\mathbf{X}}_A - \overline{\mathbf{X}}_{B}\)</span>.</p>
<p>By definition, the sampling distribution of the estimator is obtained by repeatedly generating samples <code class="docutils literal notranslate"><span class="pre">xA</span></code> and <code class="docutils literal notranslate"><span class="pre">xB</span></code> from the two distributions and computing <code class="docutils literal notranslate"><span class="pre">dmeans</span></code> on the random samples. For example, we can obtain the sampling distribution by generating <span class="math notranslate nohighlight">\(N=1000\)</span> samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_sampling_dist</span><span class="p">(</span><span class="n">statfunc</span><span class="p">,</span> <span class="n">meanA</span><span class="p">,</span> <span class="n">stdA</span><span class="p">,</span> <span class="n">nA</span><span class="p">,</span> <span class="n">meanB</span><span class="p">,</span> <span class="n">stdB</span><span class="p">,</span> <span class="n">nB</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Obtain the sampling distribution of the statistic `statfunc`</span>
<span class="sd">    from `N` random samples drawn from groups A and B with parmeters:</span>
<span class="sd">      - Group A: `nA` values taken from `norm(meanA, stdA)`</span>
<span class="sd">      - Group B: `nB` values taken from `norm(meanB, stdB)`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">stats</span> <span class="o">=</span> <span class="p">[]</span> 
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="n">xA</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">meanA</span><span class="p">,</span> <span class="n">stdA</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nA</span><span class="p">)</span>  <span class="c1"># random sample from Group A</span>
        <span class="n">xB</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">meanB</span><span class="p">,</span> <span class="n">stdB</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nB</span><span class="p">)</span>  <span class="c1"># random sample from Group B</span>
        <span class="n">stat</span> <span class="o">=</span> <span class="n">statfunc</span><span class="p">(</span><span class="n">xA</span><span class="p">,</span> <span class="n">xB</span><span class="p">)</span>         <span class="c1"># evaluate `statfunc`</span>
        <span class="n">stats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stat</span><span class="p">)</span>      <span class="c1"># record the value of statfunc</span>
    <span class="k">return</span> <span class="n">stats</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate the sampling distirbution for dmeans</span>
<span class="n">dmeans_sdist</span> <span class="o">=</span> <span class="n">get_sampling_dist</span><span class="p">(</span><span class="n">statfunc</span><span class="o">=</span><span class="n">dmeans</span><span class="p">,</span>
                                 <span class="n">meanA</span><span class="o">=</span><span class="n">muA</span><span class="p">,</span> <span class="n">stdA</span><span class="o">=</span><span class="n">sigmaA</span><span class="p">,</span> <span class="n">nA</span><span class="o">=</span><span class="n">nA</span><span class="p">,</span>
                                 <span class="n">meanB</span><span class="o">=</span><span class="n">muB</span><span class="p">,</span> <span class="n">stdB</span><span class="o">=</span><span class="n">sigmaB</span><span class="p">,</span> <span class="n">nB</span><span class="o">=</span><span class="n">nB</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Generated&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dmeans_sdist</span><span class="p">),</span> <span class="s2">&quot;values from `dmeans(XA, XB)`&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Generated 1000 values from `dmeans(XA, XB)`
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># first 3 values</span>
<span class="n">dmeans_sdist</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[np.float64(110.81313499568878),
 np.float64(113.02015528478827),
 np.float64(108.81540875963461)]
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-the-sampling-distribution-of-dmeans">
<h4>Plot the sampling distribution of <code class="docutils literal notranslate"><span class="pre">dmeans</span></code><a class="headerlink" href="#plot-the-sampling-distribution-of-dmeans" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax3</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">dmeans_sdist</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s2">&quot;density&quot;</span><span class="p">)</span>
<span class="n">title3</span> <span class="o">=</span> <span class="s2">&quot;Samping distribution of D = mean($\mathbf</span><span class="si">{X}</span><span class="s2">_A$) - mean($\mathbf</span><span class="si">{X}</span><span class="s2">_B$) &quot;</span> <span class="o">+</span> \
         <span class="s2">&quot;for samples of size $n_A$ = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">nA</span><span class="p">)</span> <span class="o">+</span> \
         <span class="s2">&quot; from $\mathcal</span><span class="si">{N}</span><span class="s2">$(&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">muA</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;,&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sigmaA</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span> <span class="o">+</span> \
         <span class="s2">&quot; and $n_B$ = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">nB</span><span class="p">)</span> <span class="o">+</span> \
         <span class="s2">&quot; from $\mathcal</span><span class="si">{N}</span><span class="s2">$(&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">muB</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;,&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sigmaB</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;)&quot;</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/626a77d0a6fc2c144d62cf944a9ac2f61d400f287e87c79f09b840adaa35517f.png"><img alt="../_images/626a77d0a6fc2c144d62cf944a9ac2f61d400f287e87c79f09b840adaa35517f.png" src="../_images/626a77d0a6fc2c144d62cf944a9ac2f61d400f287e87c79f09b840adaa35517f.png" style="width: 1030px; height: 455px;" />
</a>
</div>
</div>
</section>
<section id="theoretical-model-for-the-sampling-distribution-of-dmeans">
<h4>Theoretical model for the sampling distribution of <code class="docutils literal notranslate"><span class="pre">dmeans</span></code><a class="headerlink" href="#theoretical-model-for-the-sampling-distribution-of-dmeans" title="Link to this heading">#</a></h4>
<p>Let’s now use probability theory to build a theoretical model for the sampling distribution of the difference-between-means estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code>.</p>
<ul class="simple">
<li><p>The central limit theorem tells us the sample mean within the two group are
$<span class="math notranslate nohighlight">\(
\overline{\mathbf{X}}_A \sim \mathcal{N}\!\left(\mu_A, \tfrac{\sigma_A}{\sqrt{n_A}} \right)
\qquad \textrm{and} \qquad
\overline{\mathbf{X}}_B \sim \mathcal{N}\!\left(\mu_B, \tfrac{\sigma_B}{\sqrt{n_B}} \right).
\)</span>$</p></li>
<li><p>The rules of probability theory tells us that the <a class="reference external" href="https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables#Independent_random_variables">difference of two normal random variables</a> requires subtracting their means and adding their variance, so we get:
$<span class="math notranslate nohighlight">\(
D \sim \mathcal{N}\!\left(\mu_A - \mu_B, \  \sqrt{\tfrac{\sigma^2_A}{n_A} + \tfrac{\sigma^2_B}{n_B}} \right).
\)</span>$</p></li>
</ul>
<p>In other words, the sampling distribution for the difference between means estimator <span class="math notranslate nohighlight">\(D\)</span> has mean and standard deviation given by:
$<span class="math notranslate nohighlight">\( 
   \mu_D = \mu_A - \mu_B
   \qquad \textrm{and} \qquad
   \sigma_D = \sqrt{ \tfrac{\sigma^2_A}{n_A} + \tfrac{\sigma^2_B}{n_B}  }.
\)</span>$</p>
<p>Probability theory predicts the sampling distribution had mean …</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Dmean</span> <span class="o">=</span> <span class="n">muA</span> <span class="o">-</span> <span class="n">muB</span>
<span class="n">Dmean</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100
</pre></div>
</div>
</div>
</div>
<p>… and standard deviation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Dstd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigmaA</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nA</span> <span class="o">+</span> <span class="n">sigmaB</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nB</span><span class="p">)</span>
<span class="n">Dstd</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(10.954451150103322)
</pre></div>
</div>
</div>
</div>
<p>Let’s plot the theoretical sampling distribution
on top of the simulated data to see if they are a good fit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">dmeans_sdist</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">dmeans_sdist</span><span class="p">),</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">Dmean</span><span class="p">,</span> <span class="n">Dstd</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Theoretical sampling distribuition&#39;</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">D</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">blue</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">figure</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/d8634e3cb40768a8015a92892b11db115c16f13e8e02a1c12b63a6e7559cf115.png"><img alt="../_images/d8634e3cb40768a8015a92892b11db115c16f13e8e02a1c12b63a6e7559cf115.png" src="../_images/d8634e3cb40768a8015a92892b11db115c16f13e8e02a1c12b63a6e7559cf115.png" style="width: 1030px; height: 455px;" />
</a>
</div>
</div>
</section>
</section>
<section id="regroup-and-reality-check">
<h3>Regroup and reality check<a class="headerlink" href="#regroup-and-reality-check" title="Link to this heading">#</a></h3>
<p>How are you doing, dear readers?
I know this was a lot of math and code, but the good news is we’re done now!
The key things to remember is that we have multiple ways of computing the sampling distribution
for an estimator: using simulation or using math.
Depending on what you feel more comfortable with,
you can obtain sampling distributions either by repeatedly generating random samples from the model and compute the estimator values then plotting a histogram, or use probability theory equations to obtain an analytical formula.</p>
<section id="why-are-we-doing-all-this-modelling">
<h4>Why are we doing all this modelling?<a class="headerlink" href="#why-are-we-doing-all-this-modelling" title="Link to this heading">#</a></h4>
<p>The estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code> we defined above measures the quantity we’re interested in:
the difference between the means of two groups (<strong>Group S</strong> and <strong>Group NS</strong> in Amy’s statistical analysis of ELV data).</p>
<p>Using the functions we developed above, we now have the ability to simulate the data from any two groups by simply choosing the appropriate parameters. In particular if we choose <code class="docutils literal notranslate"><span class="pre">stdS=266</span></code>, <code class="docutils literal notranslate"><span class="pre">nS=30</span></code>; and <code class="docutils literal notranslate"><span class="pre">stdNS=233</span></code>, <code class="docutils literal notranslate"><span class="pre">nNS=31</span></code>,
we can generate random data that has similar variability to Amy ELV measurements.</p>
<p>Okay, dear reader, we’re about to jump into the deep end of the statistics pool: <strong>hypothesis testing</strong>,
which is one of the two major ideas in the STATS 101 curriculum.
Heads up this will get complicated, but we have to go into it because it is an essential procedure
that is used widely in science, engineering, business, and other types of research.
You need to trust me this one: it’s worth knowing this stuff, even if it is boring.
Don’t worry about it though, since you have all the prerequisites needed to get through this!</p>
<hr class="docutils" />
<p>Recall Amy’s research Question 1:</p>
<p>Is there a difference between ELV of the employees in <strong>Group S</strong> and the employees in <strong>Group NS</strong>?</p>
</section>
</section>
</section>
<section id="hypothesis-testing">
<h2>Hypothesis testing<a class="headerlink" href="#hypothesis-testing" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>An approach to formulating research questions as <strong>yes-no decisions</strong> and a <strong>procedure for making these decisions</strong></p></li>
<li><p>Hypothesis testing is a standardized procedure for doing statistical analysis<br />
(also, using stats jargon makes everything look more convincing ;)</p></li>
<li><p>We formulate research question as two <strong>competing hypotheses</strong>:</p>
<ul>
<li><p><strong>Null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span></strong> = no effect.<br />
In our example: “no difference between means,” which can be written as <span class="math notranslate nohighlight">\(\color{red}{\mu_S = \mu_{NS} = \mu_0}\)</span>,
means the probability models for the two groups have the same mean <span class="math notranslate nohighlight">\(\mu_0\)</span>:
$<span class="math notranslate nohighlight">\( 
   H_0: \qquad X_S = \mathcal{N}(\color{red}{\mu_0}, \sigma_S)
   \quad \textrm{and} \quad
   X_{NS} = \mathcal{N}(\color{red}{\mu_0}, \sigma_{NS}) \quad
\)</span>$</p></li>
<li><p><strong>Alternative hypothesis <span class="math notranslate nohighlight">\(H_A\)</span></strong> = an effect exists.
In our example: “the means for Group S is different from the mean of Group NS”
can be written as <span class="math notranslate nohighlight">\(\color{blue}{\mu_S} \neq \color{orange}{\mu_{NS}}\)</span>.
The probability models for the two groups with different means are:
$<span class="math notranslate nohighlight">\( 
   H_A: \qquad X_S = \mathcal{N}(\color{blue}{\mu_S}, \sigma_S)
   \quad \textrm{and} \quad
   X_{NS} = \mathcal{N}(\color{orange}{\mu_{NS}}, \sigma_{NS})
\)</span>$</p></li>
</ul>
</li>
<li><p>The purpose of hypothesis testing is to perform a basic sanity-check to show the difference between the group means
we observed (<span class="math notranslate nohighlight">\(d = \overline{\mathbf{x}}_{S} - \overline{\mathbf{x}}_{NS} = 130\)</span>) is <strong>unlikely to have occurred by chance</strong>.</p></li>
<li><p>NEW CONCEPT: the <span class="math notranslate nohighlight">\(p\)</span>-value is the probability of observing <span class="math notranslate nohighlight">\(d=130\)</span> (or more extreme) under the null hypothesis.</p></li>
</ul>
<section id="overview-of-the-hypothesis-testing-procedure">
<h3>Overview of the hypothesis testing procedure<a class="headerlink" href="#overview-of-the-hypothesis-testing-procedure" title="Link to this heading">#</a></h3>
<p>Here is the high-level overview of the hypothesis testing procedure:</p>
<ul class="simple">
<li><p><strong>inputs</strong>: sample statistics computed from the observed data
(in our case the signal <span class="math notranslate nohighlight">\(\overline{\mathbf{x}}_S\)</span>, <span class="math notranslate nohighlight">\(\overline{\mathbf{x}}_{NS}\)</span>,
and our estimates of the noise <span class="math notranslate nohighlight">\(s^2_S\)</span>, and <span class="math notranslate nohighlight">\(s^2_{NS}\)</span>)</p></li>
<li><p><strong>outputs</strong>: a decision that is one of: “reject the null hypothesis” or “fail to reject the null hypothesis”</p></li>
</ul>
<p><img alt="hypothesis testing for overview.png" src="stats_overview/figures/hypothesis%20testing%20for%20overview.png" /></p>
<p>We’ll now look at two different approaches for computing the sampling distribution of
the difference between group means statistic, <span class="math notranslate nohighlight">\(D = \overline{\mathbf{X}}_S - \overline{\mathbf{X}}_{NS}\)</span>:
permutation tests and analytical approximations.</p>
</section>
<section id="interpreting-the-result-of-a-hypothesis-test-optional">
<h3>Interpreting the result of a hypothesis test (optional)<a class="headerlink" href="#interpreting-the-result-of-a-hypothesis-test-optional" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The implication of rejecting the null hypothesis (no difference) is that there must be a difference between the group means.
In other words, the average ELV (employee lifetime value) for employees who took the statistics training (<strong>Group S</strong>) is different form
the average ELV for employees who didn’t take the statistics training (<strong>Group NS</strong>),
which is what Amy is trying to show.</p>
<ul>
<li><p>Note that rejecting null hypothesis (<span class="math notranslate nohighlight">\(H_0\)</span>) is not the same as “proving” the alternative hypothesis (<span class="math notranslate nohighlight">\(H_A\)</span>);
we have just shown that the data is unlikely under the null hypothesis,
so there must be <em>some</em> difference between the groups.
The conclusion is that it’s worth looking for <em>some</em> alternative hypothesis.</p></li>
<li><p>The alternative hypothesis we picked above, <span class="math notranslate nohighlight">\(\mu_S \neq \mu_{NS}\)</span>, is just a placeholder,
that includes desirable effect: <span class="math notranslate nohighlight">\(\mu_S &gt; \mu_{NS}\)</span> (stats training improves ELV),
but also includes the opposite effect: <span class="math notranslate nohighlight">\(\mu_S &lt; \mu_{NS}\)</span> (stats training decreases ELV).</p></li>
<li><p>Using statistics jargon, when we reject the hypothesis <span class="math notranslate nohighlight">\(H_0\)</span> we say we’ve observed a “statistically significant” result,
which sounds a lot more impressive than it actually is.
The null hypothesis testing procedure is used to just rule out “occurred by chance” scenario,
which is a very basic sanity check.</p></li>
</ul>
</li>
<li><p>The implication of failing to reject the null hypothesis is that the observed difference
between means is “not significant,” meaning it could have occurred by chance,
so there is no need to search for an alternative hypothesis.</p>
<ul>
<li><p>Note that “failing to reject” is not the same as “proving” the null hypothesis.</p></li>
<li><p>Note also that “failing to reject <span class="math notranslate nohighlight">\(H_0\)</span>” doesn’t mean we reject <span class="math notranslate nohighlight">\(H_A\)</span>.
In fact, the alternative hypothesis didn’t play any role in the calculations whatsoever.</p></li>
</ul>
</li>
</ul>
<p>I know all this sounds super complicated and roundabout (an it is!),
but you will get a hang of it with practice.
Trust me, you need to know this shit.</p>
</section>
<section id="start-by-loading-the-data-again">
<h3>Start by loading the data again…<a class="headerlink" href="#start-by-loading-the-data-again" title="Link to this heading">#</a></h3>
<p>First things first, let’s reload the cleaned data file that we prepared back in the notebook <a class="reference internal" href="01_DATA.html"><span class="std std-doc">01_DATA.ipynb</span></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/employee_lifetime_values.csv&#39;</span><span class="p">)</span>
<span class="n">data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>group</th>
      <th>ELV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NS</td>
      <td>923.87</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NS</td>
      <td>751.38</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NS</td>
      <td>432.83</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NS</td>
      <td>1417.36</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NS</td>
      <td>973.24</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>56</th>
      <td>S</td>
      <td>931.61</td>
    </tr>
    <tr>
      <th>57</th>
      <td>S</td>
      <td>1329.68</td>
    </tr>
    <tr>
      <th>58</th>
      <td>S</td>
      <td>1293.03</td>
    </tr>
    <tr>
      <th>59</th>
      <td>S</td>
      <td>1240.44</td>
    </tr>
    <tr>
      <th>60</th>
      <td>S</td>
      <td>1105.59</td>
    </tr>
  </tbody>
</table>
<p>61 rows × 2 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># remember the descriptive statistics</span>
<span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;group&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="8" halign="left">ELV</th>
    </tr>
    <tr>
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
    <tr>
      <th>group</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>NS</th>
      <td>31.0</td>
      <td>1018.41129</td>
      <td>265.815869</td>
      <td>432.83</td>
      <td>858.7750</td>
      <td>990.130</td>
      <td>1183.2750</td>
      <td>1620.93</td>
    </tr>
    <tr>
      <th>S</th>
      <td>30.0</td>
      <td>1148.43500</td>
      <td>233.037704</td>
      <td>623.06</td>
      <td>1022.1375</td>
      <td>1119.305</td>
      <td>1279.8825</td>
      <td>1716.61</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">dmeans</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the difference between groups means.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">xS</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;S&quot;</span><span class="p">][</span><span class="s2">&quot;ELV&quot;</span><span class="p">]</span>
    <span class="n">xNS</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">sample</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;NS&quot;</span><span class="p">][</span><span class="s2">&quot;ELV&quot;</span><span class="p">]</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xS</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span>

<span class="c1"># the observed value in Amy&#39;s data</span>
<span class="n">dmeans</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(130.02370967741933)
</pre></div>
</div>
</div>
</div>
<p>Our goal is to determine how <em>likely</em> or <em>unlikely</em> this observed value <span class="math notranslate nohighlight">\(d=130\)</span> is under the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span>.</p>
<p>In the next two sections, we’ll look at two different approaches for obtaining the sampling distribution of <span class="math notranslate nohighlight">\(D\)</span> under <span class="math notranslate nohighlight">\(H_0\)</span>: permutation test and analytical approximations.</p>
</section>
</section>
<section id="approach-1-permutation-test-for-comparing-two-groups">
<h2>Approach 1: Permutation test for comparing two groups<a class="headerlink" href="#approach-1-permutation-test-for-comparing-two-groups" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>The permutation test allow us to generate the sampling distribution under <span class="math notranslate nohighlight">\(H_0\)</span>
by reusing the sample <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> that we have,
treating it as if it were a population.</p></li>
<li><p>Relevant probability distributions:</p>
<ul>
<li><p>Real sampling distribution: obtained from repeated samples from a hypothetical population under <span class="math notranslate nohighlight">\(H_0\)</span>.</p></li>
<li><p>Approximate sampling distribution: obtained by <strong>resampling data from the single sample we have</strong>.</p></li>
</ul>
</li>
<li><p>Recall Goal 1: make sure that the observed difference is unlikely to have occurred by chance under <span class="math notranslate nohighlight">\(H_0\)</span>
(the difference between group means <span class="math notranslate nohighlight">\(d=130\)</span> cannot be explained by the natural variability of the distributions)</p>
<ul>
<li><p>We want to obtain an approximation of the sampling distribution under <span class="math notranslate nohighlight">\(H_0\)</span></p></li>
<li><p>The <span class="math notranslate nohighlight">\(H_0\)</span> probability model describes a hypothetical scenario with <strong>no difference between groups</strong>,
which means data from <strong>Group S</strong> and <strong>Group NS</strong> comes the same distribution.</p></li>
<li><p>To generate a new random sample <span class="math notranslate nohighlight">\(\mathbf{x}^p\)</span> from the <span class="math notranslate nohighlight">\(H_0\)</span> model,
we can reuse the sample we have obtained <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>,
but randomly mix-up the group labels.
Since under the <span class="math notranslate nohighlight">\(H_0\)</span> model, the <strong>S</strong> and <strong>NS</strong> populations are identical,
mixing up the labels should have no effect.</p></li>
<li><p>The math term for “mixing up” is <strong>permutation</strong>, meaning
each value in the input is randomly reassigned to a new random place in the output.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">resample_under_H0</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">groupcol</span><span class="o">=</span><span class="s2">&quot;group&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return a copy of the dataframe `sample` with the labels in the column `groupcol`</span>
<span class="sd">    modified based on a random permutation of the values in the original sample.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">resample</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="n">groupcol</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">newlabels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">resample</span><span class="p">[</span><span class="n">groupcol</span><span class="p">]</span> <span class="o">=</span> <span class="n">newlabels</span>
    <span class="k">return</span> <span class="n">resample</span>

<span class="n">resample_under_H0</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>group</th>
      <th>ELV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>S</td>
      <td>923.87</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NS</td>
      <td>751.38</td>
    </tr>
    <tr>
      <th>2</th>
      <td>S</td>
      <td>432.83</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NS</td>
      <td>1417.36</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NS</td>
      <td>973.24</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>56</th>
      <td>S</td>
      <td>931.61</td>
    </tr>
    <tr>
      <th>57</th>
      <td>NS</td>
      <td>1329.68</td>
    </tr>
    <tr>
      <th>58</th>
      <td>NS</td>
      <td>1293.03</td>
    </tr>
    <tr>
      <th>59</th>
      <td>S</td>
      <td>1240.44</td>
    </tr>
    <tr>
      <th>60</th>
      <td>NS</td>
      <td>1105.59</td>
    </tr>
  </tbody>
</table>
<p>61 rows × 2 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># resample</span>
<span class="n">resample</span> <span class="o">=</span> <span class="n">resample_under_H0</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># compute the difference in means for the new labels</span>
<span class="n">dmeans</span><span class="p">(</span><span class="n">resample</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(-29.60082795698918)
</pre></div>
</div>
</div>
</div>
<p>The function <code class="docutils literal notranslate"><span class="pre">resample_under_H0</span></code> gives us a way to generate samples from the null hypothesis.
We can then compute the value of the <code class="docutils literal notranslate"><span class="pre">dmeans</span></code> statistic for these samples. We used the assumption of “no difference” under the null hypothesis, and translated this to the “forget the labels” interpretation.</p>
<section id="running-a-permutation-test">
<h3>Running a permutation test<a class="headerlink" href="#running-a-permutation-test" title="Link to this heading">#</a></h3>
<p>We can repeat the resampling procedure <code class="docutils literal notranslate"><span class="pre">10000</span></code> times to get the sampling distribution of <span class="math notranslate nohighlight">\(D\)</span> under <span class="math notranslate nohighlight">\(H_0\)</span>,
as illustrated in the code procedure below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">permutation_test</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">statfunc</span><span class="p">,</span> <span class="n">groupcol</span><span class="o">=</span><span class="s2">&quot;group&quot;</span><span class="p">,</span> <span class="n">permutations</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the p-value of the observed `statfunc(sample)` under the null hypothesis</span>
<span class="sd">    where the labels in the `groupcol` are randomized.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1. compute the observed value of the statistic for the sample</span>
    <span class="n">obsstat</span> <span class="o">=</span> <span class="n">statfunc</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

    <span class="c1"># 2. generate the sampling distr. under H0</span>
    <span class="n">restats</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">permutations</span><span class="p">):</span>
        <span class="n">resample</span> <span class="o">=</span> <span class="n">resample_under_H0</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">groupcol</span><span class="o">=</span><span class="n">groupcol</span><span class="p">)</span>
        <span class="n">restat</span> <span class="o">=</span> <span class="n">statfunc</span><span class="p">(</span><span class="n">resample</span><span class="p">)</span>
        <span class="n">restats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">restat</span><span class="p">)</span>

    <span class="c1"># 3. compute p-value: how many `restat`s are equal-or-more-extreme than `obsstat`</span>
    <span class="n">tailstats</span> <span class="o">=</span> <span class="p">[</span><span class="n">restat</span> <span class="k">for</span> <span class="n">restat</span> <span class="ow">in</span> <span class="n">restats</span> \
                 <span class="k">if</span> <span class="n">restat</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">obsstat</span><span class="p">)</span> <span class="ow">or</span> <span class="n">restat</span> <span class="o">&gt;=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">obsstat</span><span class="p">)]</span>
    <span class="n">pvalue</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tailstats</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">restats</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">restats</span><span class="p">,</span> <span class="n">pvalue</span>


<span class="n">sampling_dist</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">permutation_test</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">statfunc</span><span class="o">=</span><span class="n">dmeans</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the sampling distribution in blue</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">sampling_dist</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

<span class="c1"># plot red line for the observed statistic</span>
<span class="n">obsstat</span> <span class="o">=</span> <span class="n">dmeans</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">obsstat</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="c1"># plot the values that are equal or more extreme in red</span>
<span class="n">tailstats</span> <span class="o">=</span> <span class="p">[</span><span class="n">rs</span> <span class="k">for</span> <span class="n">rs</span> <span class="ow">in</span> <span class="n">sampling_dist</span> <span class="k">if</span> <span class="n">rs</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="n">obsstat</span> <span class="ow">or</span> <span class="n">rs</span> <span class="o">&gt;=</span> <span class="n">obsstat</span><span class="p">]</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">tailstats</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="../_images/a5a32a43a4156737125dbba05ebaf6bea56eb7f4952be57a855535207fbe2e52.png"><img alt="../_images/a5a32a43a4156737125dbba05ebaf6bea56eb7f4952be57a855535207fbe2e52.png" src="../_images/a5a32a43a4156737125dbba05ebaf6bea56eb7f4952be57a855535207fbe2e52.png" style="width: 704px; height: 432px;" />
</a>
</div>
</div>
<ul class="simple">
<li><p>Once we have the sampling distribution of <code class="docutils literal notranslate"><span class="pre">D</span></code> under <span class="math notranslate nohighlight">\(H_0\)</span>,
we can see where the observed value <span class="math notranslate nohighlight">\(d=130\)</span>
falls within this distribution.</p></li>
<li><p>p-value: the probability of observing value <span class="math notranslate nohighlight">\(d=130\)</span> or more extreme under the null hypothesis</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.046
</pre></div>
</div>
</div>
</div>
<p>We can now make the decision based on the <span class="math notranslate nohighlight">\(p\)</span>-value and a pre-determined threshold:</p>
<ul class="simple">
<li><p>If the observed value <span class="math notranslate nohighlight">\(d\)</span> is unlikely under <span class="math notranslate nohighlight">\(H_0\)</span> (<span class="math notranslate nohighlight">\(p\)</span>-value less than 5% chance of occurring),
then our decision will be to “reject the null hypothesis.”</p></li>
<li><p>Otherwise, if the observed value <span class="math notranslate nohighlight">\(d\)</span> is not that unusual (<span class="math notranslate nohighlight">\(p\)</span>-value greater than 5%),
we conclude that we have “failed to reject the null hypothesis.”</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">pvalue</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DECISION: Reject H0&quot;</span><span class="p">,</span> <span class="s2">&quot;( p-value =&quot;</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">,</span> <span class="s2">&quot;)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;There is a statistically significant difference between xS and xNS&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DECISION: Fail to reject H0&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The difference between groups means could have occurred by chance&quot;</span><span class="p">)</span>    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DECISION: Reject H0 ( p-value = 0.046 )
There is a statistically significant difference between xS and xNS
</pre></div>
</div>
</div>
</div>
</section>
<section id="permutations-test-using-scipy">
<h3>Permutations test using SciPy<a class="headerlink" href="#permutations-test-using-scipy" title="Link to this heading">#</a></h3>
<p>The above code was given only for educational purposes.
In practice, you can use the SciPy implementation of permutation test,
by calling <code class="docutils literal notranslate"><span class="pre">ttest_ind(...,</span> <span class="pre">permutations=10000)</span></code> to perform a permutation test, then obtain the <span class="math notranslate nohighlight">\(p\)</span>-value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">ttest_ind</span>

<span class="n">xS</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;S&quot;</span><span class="p">][</span><span class="s2">&quot;ELV&quot;</span><span class="p">]</span>
<span class="n">xNS</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;NS&quot;</span><span class="p">][</span><span class="s2">&quot;ELV&quot;</span><span class="p">]</span>

<span class="n">ttest_ind</span><span class="p">(</span><span class="n">xS</span><span class="p">,</span> <span class="n">xNS</span><span class="p">,</span> <span class="n">permutations</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_11345/2508911715.py:6: DeprecationWarning: Arguments {&#39;permutations&#39;} are deprecated, whether passed by position or keyword. They will be removed in SciPy 1.17.0. Use ``method`` to perform a permutation test.
  ttest_ind(xS, xNS, permutations=10000).pvalue
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.044795520447955206)
</pre></div>
</div>
</div>
</div>
<p>Note the <span class="math notranslate nohighlight">\(p\)</span>-value we obtained form the two methods is slightly different:
this is going to be the case for all resampling methods and simulations,
since use randomness as part of the calculation.</p>
</section>
<section id="discussion">
<h3>Discussion<a class="headerlink" href="#discussion" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>The procedure we used is called a <strong>permutations test</strong> for comparison of group means.</p></li>
<li><p>The permutation test takes it’s name from the action of mixing up the group-membership labels
and computing a statistic which is a way to generate samples from the null hypothesis
in situations where we’re comparing two groups.</p></li>
<li><p>Permutation tests are very versatile since we can use them for any estimator <span class="math notranslate nohighlight">\(g(\mathbf{x})\)</span>.
For example, we could have used difference in medians by specifying the <code class="docutils literal notranslate"><span class="pre">median</span></code> as the input <code class="docutils literal notranslate"><span class="pre">statfunc</span></code>.</p></li>
</ul>
</section>
</section>
<section id="approach-2-analytical-approximations-for-hypothesis-testing">
<h2>Approach 2: Analytical approximations for hypothesis testing<a class="headerlink" href="#approach-2-analytical-approximations-for-hypothesis-testing" title="Link to this heading">#</a></h2>
<p>We’ll now look at another approach for answering Question 1:
using and analytical approximation,
which is the way normally taught in STATS 101 courses.
How likely or unlikely is the observed difference <span class="math notranslate nohighlight">\(d=130\)</span> under the null hypothesis?</p>
<ul class="simple">
<li><p>Analytical approximations are math models for describing the sampling distribution under <span class="math notranslate nohighlight">\(H_0\)</span></p>
<ul>
<li><p>Real sampling distributions: obtained by repeated sampling from <span class="math notranslate nohighlight">\(H_0\)</span></p></li>
<li><p>Analytical approximation: probability model based on estimated parameters</p></li>
</ul>
</li>
<li><p>Based on this assumption we can use the theoretical model for the difference between group means
that we developed earlier, we can obtain a <strong>closed form expression</strong> for the sampling distribution of <span class="math notranslate nohighlight">\(D\)</span>.</p></li>
<li><p>In particular, the probability model for the two groups under <span class="math notranslate nohighlight">\(H_0\)</span> are:
$<span class="math notranslate nohighlight">\( 
     H_0: \qquad X_S = \mathcal{N}(\color{red}{\mu_0}, \sigma_S)
     \quad \textrm{and} \quad
     X_{NS} = \mathcal{N}(\color{red}{\mu_0}, \sigma_{NS}), \quad
\)</span><span class="math notranslate nohighlight">\(
from which we can derive the model for \)</span>D = \overline{\mathbf{X}}<em>S - \overline{\mathbf{X}}</em>{NS}<span class="math notranslate nohighlight">\(:
\)</span><span class="math notranslate nohighlight">\( 
   D  \sim \mathcal{N}\!\left( \color{red}{0}, \  \sqrt{ \tfrac{\sigma^2_S}{n_S} + \tfrac{\sigma^2_{NS}}{n_{NS}} } \right)
\)</span><span class="math notranslate nohighlight">\(
In words, the sampling distribution of the difference between group means is
normally distributed with mean \)</span>\mu_D = 0<span class="math notranslate nohighlight">\( and standard deviation \)</span>\sigma_D<span class="math notranslate nohighlight">\(,
which depends on the variance of the two groups \)</span>\sigma^2_S<span class="math notranslate nohighlight">\( and \)</span>\sigma^2_{NS}$.
Recall we obtained this expression earlier when we discussed difference of means between groups A and B.</p></li>
<li><p>However, the population variances <span class="math notranslate nohighlight">\(\sigma^2_S\)</span> and <span class="math notranslate nohighlight">\(\sigma^2_{NS}\)</span> are unknown,
and we only have the estimated variances <span class="math notranslate nohighlight">\(s_S^2\)</span> and <span class="math notranslate nohighlight">\(s_{NS}^2\)</span>,
which we calculated from the sample.</p></li>
<li><p>That’s OK though, since the sample variances are estimates for the population variances.
There are two common ways to obtain an approximation for <span class="math notranslate nohighlight">\(\sigma^2_D\)</span>:</p>
<ul>
<li><p>Pooled variance: <span class="math notranslate nohighlight">\(\sigma^2_D \approx s^2_p =  \frac{(n_S-1)s_S^2 \; + \; (n_{NS}-1)s_{NS}^2}{n_S + n_{NS} - 2}\)</span>
(takes advantage of assumption that both samples come from the same population under <span class="math notranslate nohighlight">\(H_0\)</span>)</p></li>
<li><p>Unpooled variance: <span class="math notranslate nohighlight">\(\sigma^2_D \approx s^2_u = \tfrac{s^2_S}{n_S} + \tfrac{s^2_{NS}}{n_{NS}}\)</span>
(follows from the general rule of probability theory)</p></li>
</ul>
</li>
<li><p>NEW CONCEPT: <strong>Student’s <span class="math notranslate nohighlight">\(t\)</span>-distribution</strong> is a model for <span class="math notranslate nohighlight">\(D\)</span> which takes into account
we are using <span class="math notranslate nohighlight">\(s_S^2\)</span> and <span class="math notranslate nohighlight">\(s_{NS}^2\)</span> instead of <span class="math notranslate nohighlight">\(\sigma_S^2\)</span> and <span class="math notranslate nohighlight">\(\sigma_{NS}^2\)</span>.</p></li>
<li><p>NEW CONCEPT: <strong>degrees of freedom</strong>, denoted <code class="docutils literal notranslate"><span class="pre">df</span></code> in code or <span class="math notranslate nohighlight">\(\nu\)</span> (Greek letter <em>nu</em>) in equations,
is the parameter of Student’s <span class="math notranslate nohighlight">\(t\)</span>-distribution dependent on the sample size used to estimate quantities.</p></li>
</ul>
<section id="student-s-t-test-pooled-variance">
<h3>Student’s t-test (pooled variance)<a class="headerlink" href="#student-s-t-test-pooled-variance" title="Link to this heading">#</a></h3>
<p><a class="reference external" href="https://statkat.com/stattest.php?&amp;amp;t=9">Student’s <span class="math notranslate nohighlight">\(t\)</span>-test for comparison of the difference between two groups means</a> is a procedure that makes use of the pooled variance <span class="math notranslate nohighlight">\(s^2_p\)</span>.
Recall <span class="math notranslate nohighlight">\(H_0\)</span> states there is no difference between the two groups.
This means we can think of <span class="math notranslate nohighlight">\(s_S^2\)</span> and <span class="math notranslate nohighlight">\(s_{NS}^2\)</span> as two independent estimates of the population variance,
so we can combine them (pool them together) to obtain an estimate <span class="math notranslate nohighlight">\(s^2_p\)</span>.</p>
<section id="black-box-approach">
<h4>Black-box approach<a class="headerlink" href="#black-box-approach" title="Link to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> function <code class="docutils literal notranslate"><span class="pre">ttest_ind</span></code> will perform all the steps of Student’s <span class="math notranslate nohighlight">\(t\)</span>-test procedure,
without the need for us to understand the details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">ttest_ind</span>

<span class="c1"># extract data for two groups</span>
<span class="n">xS</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;S&quot;</span><span class="p">][</span><span class="s1">&#39;ELV&#39;</span><span class="p">]</span>
<span class="n">xNS</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;NS&quot;</span><span class="p">][</span><span class="s1">&#39;ELV&#39;</span><span class="p">]</span>

<span class="c1"># run the complete t-test procedure for ind-ependent samples:</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">ttest_ind</span><span class="p">(</span><span class="n">xS</span><span class="p">,</span> <span class="n">xNS</span><span class="p">)</span>
<span class="n">result</span><span class="o">.</span><span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.046999086677830995)
</pre></div>
</div>
</div>
</div>
<p>The <span class="math notranslate nohighlight">\(p\)</span>-value is less than 0.05 so our decision is to <strong>reject the null hypothesis</strong>.</p>
</section>
<section id="student-s-t-test-under-the-hood">
<h4>Student’s t-test under the hood<a class="headerlink" href="#student-s-t-test-under-the-hood" title="Link to this heading">#</a></h4>
<p>The computations hidden behind the function <code class="docutils literal notranslate"><span class="pre">ttest_ind</span></code> involve a six step procedure that makes use of the pooled variance <span class="math notranslate nohighlight">\(s^2_p\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">statistics</span><span class="w"> </span><span class="kn">import</span> <span class="n">stdev</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">t</span> <span class="k">as</span> <span class="n">tdist</span>

<span class="c1"># 1. calculate the mean in each group</span>
<span class="n">meanS</span><span class="p">,</span> <span class="n">meanNS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>

<span class="c1"># 2. calculate d, the observed difference between means</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">meanS</span> <span class="o">-</span> <span class="n">meanNS</span>

<span class="c1"># 3. calculate the standard deviations in each group</span>
<span class="n">stdS</span><span class="p">,</span> <span class="n">stdNS</span> <span class="o">=</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
<span class="n">nS</span><span class="p">,</span> <span class="n">nNS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>

<span class="c1"># 4. compute the pooled variance and standard error</span>
<span class="n">var_pooled</span> <span class="o">=</span> <span class="p">((</span><span class="n">nS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">nNS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nS</span> <span class="o">+</span> <span class="n">nNS</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">std_pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_pooled</span><span class="p">)</span>
<span class="n">std_err</span> <span class="o">=</span> <span class="n">std_pooled</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span>

<span class="c1"># 5. compute the value of the t-statistic</span>
<span class="n">tstat</span> <span class="o">=</span> <span class="n">d</span> <span class="o">/</span> <span class="n">std_err</span>

<span class="c1"># 6. obtain the p-value for the t-statistic from a </span>
<span class="c1">#    t-distribution with 31+30-2 = 59 degrees of freedom</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">nS</span> <span class="o">+</span> <span class="n">nNS</span> <span class="o">-</span> <span class="mi">2</span>
<span class="n">pvalue</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">tdist</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">tstat</span><span class="p">))</span>  <span class="c1"># 2* because two-sided</span>

<span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.04699908667783097)
</pre></div>
</div>
</div>
</div>
</section>
<section id="welch-s-t-test-unpooled-variances">
<h4>Welch’s t-test (unpooled variances)<a class="headerlink" href="#welch-s-t-test-unpooled-variances" title="Link to this heading">#</a></h4>
<p>An <a class="reference external" href="https://statkat.com/stattest.php?&amp;amp;t=9">alternative <span class="math notranslate nohighlight">\(t\)</span>-test procedure</a> that doesn’t assume the variances in the two groups are equal.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result2</span> <span class="o">=</span> <span class="n">ttest_ind</span><span class="p">(</span><span class="n">xS</span><span class="p">,</span> <span class="n">xNS</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">result2</span><span class="o">.</span><span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.04657901982704139)
</pre></div>
</div>
</div>
</div>
<p>Welch’s <span class="math notranslate nohighlight">\(t\)</span>-test differs only in steps 4 through 6 as shown below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4&#39;. compute the unpooled standard deviation of D</span>
<span class="n">stdD</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span>

<span class="c1"># 5&#39;. compute the value of the t-statistic</span>
<span class="n">tstat</span> <span class="o">=</span> <span class="n">d</span> <span class="o">/</span> <span class="n">stdD</span>

<span class="c1"># 6&#39;. obtain the p-value from a t-distribution from</span>
<span class="c1"># this crazy formula for the degrees of freedom:</span>
<span class="n">df</span> <span class="o">=</span> <span class="p">(</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> \
    <span class="p">((</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">nS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">nNS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>
<span class="n">pvalue</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">tdist</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">tstat</span><span class="p">))</span>  <span class="c1"># 2* because two-sided</span>

<span class="n">pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.04657901982704139)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="summary-of-question-1">
<h3>Summary of Question 1<a class="headerlink" href="#summary-of-question-1" title="Link to this heading">#</a></h3>
<p>We saw two ways to answer Question 1 (is there really a difference between group means) and obtain the <span class="math notranslate nohighlight">\(p\)</span>-value.
We interpreted the small <span class="math notranslate nohighlight">\(p\)</span>-values as evidence that the observed difference, <span class="math notranslate nohighlight">\(d=130\)</span>, is unlikely to be due to chance under <span class="math notranslate nohighlight">\(H_0\)</span>, so we rejected the null hypothesis.
Note this whole procedure is just a sanity check—we haven’t touched the alternative hypothesis at all yet,
and for all we know the stats training could have the effect of decreasing ELV!</p>
<hr class="docutils" />
<p>It’s time to study Question 2, which is to estimate the <em>magnitude</em> of the change in ELV obtained from completing the stats training. We call this the <em>effect size</em> in statistics.</p>
</section>
</section>
<section id="estimating-the-effect-size">
<h2>Estimating the effect size<a class="headerlink" href="#estimating-the-effect-size" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Question 2 of Amy’s statistical investigation is to estimate the difference in ELV gained by stats training.</p></li>
<li><p>NEW CONCEPT: <strong>effect size</strong> is a measure of difference between intervention and control groups.</p></li>
<li><p>We assume the data of <strong>Group S</strong> and <strong>Group NS</strong> come from different populations with means <span class="math notranslate nohighlight">\(\mu_S\)</span> and <span class="math notranslate nohighlight">\(\mu_{NS}\)</span>.</p></li>
<li><p>We’re interested in estimating the difference between population means, denoted <span class="math notranslate nohighlight">\(\Delta = \mu_S - \mu_{NS}\)</span>.</p></li>
<li><p>By analyzing the sample, we have obtained an estimate <span class="math notranslate nohighlight">\(d=130\)</span> for the unknown <span class="math notranslate nohighlight">\(\Delta\)</span>,
but we know our data contains lots of variability, so we know our estimate might be off.</p></li>
<li><p>We want an answer to Question 2 (What is the estimated difference between group means?)
that takes into account the variability of the data.</p></li>
<li><p>NEW CONCEPT: <strong>confidence interval</strong> is a way to describe a range of values for an estimate
that takes into account the variability of the data.</p></li>
<li><p>We want to provide an answer to Question 2 in the form of a confidence interval that tells
us a range of values where we believe the true value of <span class="math notranslate nohighlight">\(\Delta\)</span> falls.</p></li>
<li><p>Similar to how we showed two approaches for hypothesis testing,
we’ll work on effect size estimation using two approaches: bootstrap estimation and analytical approximation methods.</p></li>
</ul>
<section id="approach-1-confidence-intervals-using-bootstrap-estimation">
<h3>Approach 1: Confidence intervals using bootstrap estimation<a class="headerlink" href="#approach-1-confidence-intervals-using-bootstrap-estimation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>We want to estimate the distribution of ELV values for the two groups,
and compute the difference between the means of these distributions.</p></li>
<li><p>Distributions:</p>
<ul>
<li><p>Real sampling distributions: obtained by repeated sampling from the populations</p></li>
<li><p>Bootstrap sampling distributions: resampling data from the samples we have (with replacement)</p></li>
</ul>
</li>
<li><p>Intuition: treat the samples as if they were the population</p></li>
<li><p>We’ll compute <span class="math notranslate nohighlight">\(B=5000\)</span> bootstrap samples from the two groups and compute the differences.
We’ll then look at the distribution of the bootstrap sample differences to obtain
the confidence interval for the difference between population means <span class="math notranslate nohighlight">\(CI_{\Delta}\)</span>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">bootstrap_stat</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">statfunc</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the bootstrap estimate of the function `statfunc`</span>
<span class="sd">    from the data in `sample`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">bstats</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>
        <span class="n">bsample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">sample</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
        <span class="n">bstat</span> <span class="o">=</span> <span class="n">statfunc</span><span class="p">(</span><span class="n">bsample</span><span class="p">)</span>
        <span class="n">bstats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bstat</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bstats</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">statistics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean</span>

<span class="c1"># load data for two groups</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/employee_lifetime_values.csv&#39;</span><span class="p">)</span>
<span class="n">xS</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;S&quot;</span><span class="p">][</span><span class="s1">&#39;ELV&#39;</span><span class="p">]</span>
<span class="n">xNS</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;group&quot;</span><span class="p">]</span><span class="o">==</span><span class="s2">&quot;NS&quot;</span><span class="p">][</span><span class="s1">&#39;ELV&#39;</span><span class="p">]</span>

<span class="c1"># compute bootstrap estimates for mean in each group</span>
<span class="n">meanS_bstats</span> <span class="o">=</span> <span class="n">bootstrap_stat</span><span class="p">(</span><span class="n">xS</span><span class="p">,</span> <span class="n">statfunc</span><span class="o">=</span><span class="n">mean</span><span class="p">)</span>
<span class="n">meanNS_bstats</span> <span class="o">=</span> <span class="n">bootstrap_stat</span><span class="p">(</span><span class="n">xNS</span><span class="p">,</span> <span class="n">statfunc</span><span class="o">=</span><span class="n">mean</span><span class="p">)</span>

<span class="c1"># compute the difference between means from bootstrap samples</span>
<span class="n">dmeans_bstats</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">bmeanS</span><span class="p">,</span> <span class="n">bmeanNS</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">meanS_bstats</span><span class="p">,</span> <span class="n">meanNS_bstats</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">bmeanS</span> <span class="o">-</span> <span class="n">bmeanNS</span> 
    <span class="n">dmeans_bstats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">dmeans_bstats</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: ylabel=&#39;Count&#39;&gt;
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/67a363659ca6c6ebcae11784d3f7eb705a8ad0cd7f34a4971b0004311ebf505c.png"><img alt="../_images/67a363659ca6c6ebcae11784d3f7eb705a8ad0cd7f34a4971b0004311ebf505c.png" src="../_images/67a363659ca6c6ebcae11784d3f7eb705a8ad0cd7f34a4971b0004311ebf505c.png" style="width: 704px; height: 432px;" />
</a>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 90% confidence interval for the difference in means</span>
<span class="n">CI_boot</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">dmeans_bstats</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
           <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">dmeans_bstats</span><span class="p">,</span> <span class="mi">95</span><span class="p">)]</span>
<span class="n">CI_boot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[np.float64(28.3957801075268), np.float64(237.55493602150537)]
</pre></div>
</div>
</div>
</div>
<p>The 90% confidence interval <code class="docutils literal notranslate"><span class="pre">CI_boot</span></code> describes an interval of numbers
that should contain the difference between group means <span class="math notranslate nohighlight">\(\Delta\)</span> at least 90% of the time:
$<span class="math notranslate nohighlight">\(
    \textrm{Pr}_{R}\big(\{ \Delta \in \textrm{CI}_{\Delta} \}\big) \geq 0.9.
\)</span><span class="math notranslate nohighlight">\(
This is a little weird:
in any given experiment,
the unknown difference between groups \)</span>\Delta<span class="math notranslate nohighlight">\( either *is* or *isn't* in the interval \)</span>\textrm{CI}_{\Delta}<span class="math notranslate nohighlight">\(,
so what is 90\% probability referring to?
The randomness \)</span>R$ describes repeated experiments using the same calculation procedure for calculating the confidence interval.
So it is not a guarantee on any particular estimate,
but reliability of the procedure in the long term.
This is the <em>frequentist statistics</em> paradigm,
in which “quality guarantees” are given about the procedure used to obtain the estimates,
and not about particular outcomes of the procedure.</p>
<section id="scipy-bootstrap-method">
<h4>SciPy bootstrap method<a class="headerlink" href="#scipy-bootstrap-method" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">bootstrap</span>

<span class="k">def</span><span class="w"> </span><span class="nf">dmeans2</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">sample2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample1</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample2</span><span class="p">)</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">bootstrap</span><span class="p">((</span><span class="n">xS</span><span class="p">,</span> <span class="n">xNS</span><span class="p">),</span> <span class="n">statistic</span><span class="o">=</span><span class="n">dmeans2</span><span class="p">,</span> <span class="n">vectorized</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">n_resamples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;percentile&#39;</span><span class="p">)</span>

<span class="n">CI_boot2</span> <span class="o">=</span> <span class="p">[</span><span class="n">res</span><span class="o">.</span><span class="n">confidence_interval</span><span class="o">.</span><span class="n">low</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">confidence_interval</span><span class="o">.</span><span class="n">high</span><span class="p">]</span>
<span class="n">CI_boot2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[np.float64(26.55480537634374), np.float64(234.32339731182762)]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="approach-2-confidence-intervals-using-analytical-approximations">
<h3>Approach 2: Confidence intervals using analytical approximations<a class="headerlink" href="#approach-2-confidence-intervals-using-analytical-approximations" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Assumption: the variance of the two populations is the same (or approximately equal)</p></li>
<li><p>Using the theoretical model for the populations,
we can obtain a formula for CI of effect size <span class="math notranslate nohighlight">\(\Delta\)</span>:
$<span class="math notranslate nohighlight">\(
\textrm{CI}_{(1-\alpha)}
= \left[ d - t^*\!\cdot\!\sigma_D, \, 
         d + t^*\!\cdot\!\sigma_D
  \right].
\)</span><span class="math notranslate nohighlight">\(
The confidence interval is centred at \)</span>d<span class="math notranslate nohighlight">\(,
with width proportional to the standard deviation \)</span>\sigma_D<span class="math notranslate nohighlight">\(.
The constant \)</span>t^<em><span class="math notranslate nohighlight">\( denotes the value of the inverse CDF of Student's \)</span>t<span class="math notranslate nohighlight">\(-distribution
with appropriate number of degrees of freedom `df` evaluated at \)</span>1-\frac{\alpha}{2}<span class="math notranslate nohighlight">\(.
For a 90% confidence interval, we choose \)</span>\alpha=0.10<span class="math notranslate nohighlight">\(,
which gives \)</span>(1-\frac{\alpha}{2}) = 0.95<span class="math notranslate nohighlight">\(, \)</span>t^</em> = F_{T_{\textrm{df}}}^{-1}\left(0.95\right)$.</p></li>
<li><p>We can use the two different analytical approximations to obtain a formula for <span class="math notranslate nohighlight">\(\sigma_D\)</span>
just as we did in the hypothesis testing:</p>
<ul>
<li><p>Pooled variance: <span class="math notranslate nohighlight">\(\sigma^2_p =  \frac{(n_S-1)s_S^2 + (n_{NS}-1)s_{NS}^2}{n_S + n_{NS} - 2}\)</span>,
and <code class="docutils literal notranslate"><span class="pre">df</span></code> = <span class="math notranslate nohighlight">\(n_S + n_{NS} -2\)</span></p></li>
<li><p>Unpooled variance: <span class="math notranslate nohighlight">\(\sigma^2_u = \tfrac{s^2_A}{n_A} + \tfrac{s^2_B}{n_B}\)</span>, and <code class="docutils literal notranslate"><span class="pre">df</span></code> = <a class="reference external" href="https://en.wikipedia.org/wiki/Student%27s_t-test#Equal_or_unequal_sample_sizes,_unequal_variances_(sX1_%3E_2sX2_or_sX2_%3E_2sX1)">…</a></p></li>
</ul>
</li>
</ul>
<section id="using-pooled-variance">
<h4>Using pooled variance<a class="headerlink" href="#using-pooled-variance" title="Link to this heading">#</a></h4>
<p>The calculations are similar to Student’s t-test for hypothesis testing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">t</span>

<span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xS</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>

<span class="n">nS</span><span class="p">,</span> <span class="n">nNS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
<span class="n">stdS</span><span class="p">,</span> <span class="n">stdNS</span> <span class="o">=</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
<span class="n">var_pooled</span> <span class="o">=</span> <span class="p">((</span><span class="n">nS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">nNS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nS</span> <span class="o">+</span> <span class="n">nNS</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">std_pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_pooled</span><span class="p">)</span>
<span class="n">std_err</span> <span class="o">=</span> <span class="n">std_pooled</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="mi">1</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">nS</span> <span class="o">+</span> <span class="n">nNS</span> <span class="o">-</span> <span class="mi">2</span>

<span class="c1"># for 90% confidence interval, need 10% in tails</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.10</span>

<span class="c1"># now use inverse-CDF of Students t-distribution</span>
<span class="n">tstar</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">t</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

<span class="n">CI_tpooled</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="o">-</span> <span class="n">tstar</span><span class="o">*</span><span class="n">std_err</span><span class="p">,</span> <span class="n">d</span> <span class="o">+</span> <span class="n">tstar</span><span class="o">*</span><span class="n">std_err</span><span class="p">]</span>
<span class="n">CI_tpooled</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[np.float64(22.92513028437169), np.float64(237.122289070467)]
</pre></div>
</div>
</div>
</div>
</section>
<section id="using-unpooled-variance">
<h4>Using unpooled variance<a class="headerlink" href="#using-unpooled-variance" title="Link to this heading">#</a></h4>
<p>The calculations are similar to the Welch’s t-test for hypothesis testing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xS</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>

<span class="n">nS</span><span class="p">,</span> <span class="n">nNS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
<span class="n">stdS</span><span class="p">,</span> <span class="n">stdNS</span> <span class="o">=</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xS</span><span class="p">),</span> <span class="n">stdev</span><span class="p">(</span><span class="n">xNS</span><span class="p">)</span>
<span class="n">stdD</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="p">(</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span> <span class="o">+</span> <span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> \
    <span class="p">((</span><span class="n">stdS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">nS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">stdNS</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">nNS</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">nNS</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">)</span>

<span class="c1"># for 90% confidence interval, need 10% in tails</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.10</span>

<span class="c1"># now use inverse-CDF of Students t-distribution</span>
<span class="n">tstar</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">t</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

<span class="n">CI_tunpooled</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="o">-</span> <span class="n">tstar</span><span class="o">*</span><span class="n">stdD</span><span class="p">,</span> <span class="n">d</span> <span class="o">+</span> <span class="n">tstar</span><span class="o">*</span><span class="n">stdD</span><span class="p">]</span>
<span class="n">CI_tunpooled</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[np.float64(23.14219838113216), np.float64(236.9052209737065)]
</pre></div>
</div>
</div>
</div>
</section>
<section id="summary-of-question-2-results">
<h4>Summary of Question 2 results<a class="headerlink" href="#summary-of-question-2-results" title="Link to this heading">#</a></h4>
<p>We now have all the information we need to give a precise and nuanced answer to Question 2: “How big is the increase in ELV produced by stats training?”.</p>
<p>The basic estimate of the difference is <span class="math notranslate nohighlight">\(130\)</span> can be reported, and additionally can can report the 90% confidence interval for the difference between group means, that takes into account the variability in the data we have observed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CI_boot</span><span class="p">,</span> <span class="n">CI_boot2</span><span class="p">,</span> <span class="n">CI_tpooled</span><span class="p">,</span> <span class="n">CI_tunpooled</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>([np.float64(28.3957801075268), np.float64(237.55493602150537)],
 [np.float64(26.55480537634374), np.float64(234.32339731182762)],
 [np.float64(22.92513028437169), np.float64(237.122289070467)],
 [np.float64(23.14219838113216), np.float64(236.9052209737065)])
</pre></div>
</div>
</div>
</div>
<p>Note the CIs obtained using different approaches are all similar (+/- 5 ELV points), so it doesn’t matter much which approach we use.</p>
<p>Note also the CIs are very wide: the observed difference is <span class="math notranslate nohighlight">\(d=130\)</span>,
but the standard deviation of the measurements in the two groups are <span class="math notranslate nohighlight">\(s_S = 266\)</span> and <span class="math notranslate nohighlight">\(s_{NS} = 233\)</span>,
which is a lot of “noise.”</p>
</section>
</section>
<section id="standardized-effect-size-optional">
<h3>Standardized effect size (optional)<a class="headerlink" href="#standardized-effect-size-optional" title="Link to this heading">#</a></h3>
<p>It is sometimes useful to report the effect size using a “standardized” measure for effect sizes.
<em>Cohen’s <span class="math notranslate nohighlight">\(d\)</span></em> one such measure, and it is defined as the difference between two means divided by the pooled  standard deviation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">cohend</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">sample2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Cohen&#39;s d measure of effect size for two independent samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n1</span><span class="p">,</span> <span class="n">n2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample1</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample2</span><span class="p">)</span>
    <span class="n">mean1</span><span class="p">,</span> <span class="n">mean2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample2</span><span class="p">)</span>
    <span class="n">var1</span><span class="p">,</span> <span class="n">var2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">sample2</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># calculate the pooled variance and standard deviaiton</span>
    <span class="n">var_pooled</span> <span class="o">=</span> <span class="p">((</span><span class="n">n1</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">var1</span> <span class="o">+</span> <span class="p">(</span><span class="n">n2</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">var2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n1</span> <span class="o">+</span> <span class="n">n2</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">std_pooled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var_pooled</span><span class="p">)</span>
    <span class="c1"># compute Cohen&#39;s d</span>
    <span class="n">cohend</span> <span class="o">=</span> <span class="p">(</span><span class="n">mean1</span> <span class="o">-</span> <span class="n">mean2</span><span class="p">)</span> <span class="o">/</span> <span class="n">std_pooled</span>
    <span class="k">return</span> <span class="n">cohend</span>

<span class="n">cohend</span><span class="p">(</span><span class="n">xS</span><span class="p">,</span> <span class="n">xNS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(0.5195925482978414)
</pre></div>
</div>
</div>
</div>
<p>We can interpret the value of Cohen’s d obtained using the <a class="reference external" href="https://en.wikipedia.org/wiki/Effect_size#Cohen's_d">reference table</a> of values:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Cohen’s d</p></th>
<th class="head"><p>Effect size</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0.01</p></td>
<td><p>very small</p></td>
</tr>
<tr class="row-odd"><td><p>0.20</p></td>
<td><p>small</p></td>
</tr>
<tr class="row-even"><td><p>0.50</p></td>
<td><p>medium</p></td>
</tr>
<tr class="row-odd"><td><p>0.80</p></td>
<td><p>large</p></td>
</tr>
</tbody>
</table>
</div>
<p>We can therefore say the effect size of offering statistics training for employees has an <strong>medium</strong> effect size.</p>
</section>
</section>
<section id="conclusion-of-amy-s-statistical-analysis">
<h2>Conclusion of Amy’s statistical analysis<a class="headerlink" href="#conclusion-of-amy-s-statistical-analysis" title="Link to this heading">#</a></h2>
<p>Recall the two research questions that Amy set out to answer in the beginning of this video series:</p>
<ul class="simple">
<li><p>Question 1: Is there a difference between the means in the two groups?</p></li>
<li><p>Question 2: How much does statistics training improve the ELV of employees?</p></li>
</ul>
<p>The statistical analysis we did allows us to answer these two questions as follows:</p>
<ul class="simple">
<li><p>Answer 1: There is a statistically significant difference between Group S and Group NS, <span class="math notranslate nohighlight">\(p = 0.048\)</span>.</p></li>
<li><p>Answer 2: The estimated improvement in ELV is 130 points, which is corresponds to Cohen’s d value of <span class="math notranslate nohighlight">\(0.52\)</span> (medium effect size). A 90% confidence interval for the true effect size is <span class="math notranslate nohighlight">\([28.4, 237.6]\)</span>.</p></li>
</ul>
<p>Note: we reported the numerical results obtained from resampling methods (Approach 1), but conclusions would be qualitatively the same if we reported results obtained from analytical approximations (Approach 2).</p>
<section id="using-statistics-for-convincing-others">
<h3>Using statistics for convincing others<a class="headerlink" href="#using-statistics-for-convincing-others" title="Link to this heading">#</a></h3>
<p>You may be wondering if all this probabilistic modelling and complicated statistical analysis was worth it to reach a conclusion that seems obvious in retrospect. Was all this work worth it? The purpose of all this work is to obtains something close to an objective conclusion. Without statistics it is very easy to fool ourselves and interpret patterns in data the way we want to, or alternatively, not see patterns that are present. By following the standard statistical procedures, we’re less likely to fool ourselves, and more likely to be able to convince others.</p>
<p>It can be very useful to imagine Amy explaining the results to a skeptical colleague. Suppose the colleague is very much against the idea of statistical training, and sees it as a distraction, saying things like “We hire employees to do a job, not to play with Python.” and “I don’t know any statistics and I’m doing my job just fine!” You get the picture.</p>
<p>Imagine Amy presenting her findings about how 100 hours of statistical training improves employee lifetime value (ELV) results after one year, and suggesting the statistical training be implemented for all new hires from now on. The skeptical colleague immediately rejects the idea and questions Amy’s recommendation using emotional appeals about necessity, time wasting, and how statistics is a specialty topic that is not required for all employees. Instead of arguing based on opinions and emotions with her colleague, Amy explains her recommendation is based on a statistical experiment she conducted, and shows the results:</p>
<ul class="simple">
<li><p>When the colleague asks if the observed difference could be due to chance, Amy says that this is unlikely, and quotes the <span class="math notranslate nohighlight">\(p\)</span>-value of 0.048 (less than 0.05), and interprets the result as saying the probability of the observed difference between <strong>Group S</strong> and <strong>Group NS</strong> being due to chance is less than 5%.</p></li>
<li><p>The skeptical colleague is forced to concede that statistical training does improve ELV, but then asks about the effect size of the improvement: “How much more ELV can we expect if we provide statistics training?” Amy is ready to answer quoting the observed difference of <span class="math notranslate nohighlight">\(130\)</span> ELV points, and further specifies the 90% confidence interval of <span class="math notranslate nohighlight">\([28.4, 237.6]\)</span> for the improvement, meaning in the worst case there is 28 ELV points improvement.</p></li>
</ul>
<p>The skeptic is forced to back down from their objections, and the “stats training for all” program is adopted in the company. Not only was Amy able to win the argument using statistics, but she was also able to set appropriate expectations for the results. In other words, she hasn’t promised a guaranteed +130 ELV improvement, but a realistic range of values that can be expected.</p>
</section>
</section>
<section id="comparison-of-resampling-methods-and-analytical-approximations">
<h2>Comparison of resampling methods and analytical approximations<a class="headerlink" href="#comparison-of-resampling-methods-and-analytical-approximations" title="Link to this heading">#</a></h2>
<p>In this notebook we saw two different approaches for doing statistical analysis: resampling methods and analytical approximations. This is a general pattern in statistics where there is not only one correct answer: multiple approaches to data analysis are valid, and you need to think about the specifics of each situation. We’ll learn about both approaches in the book.</p>
<p>Analytical approximations are currently taught in most stats courses (STAT 101). Historically, analytical approximations have been used more widely because they require only simple arithmetic calculations: statistic practitioners (scientists, engineers, etc.) simply need to compute sample statistics, plug them into a formula, and obtain a <span class="math notranslate nohighlight">\(p\)</span>-value. This convenience comes at the cost of numerous assumptions about the data distribution, which often don’t hold in practice (e.g. assuming population is normal, when it isn’t).</p>
<p>In recent years, resampling methods like the permutation test and bootstrap estimation are becoming more popular, widely used in industry, and increasingly also taught at universities (see this <a class="reference external" href="https://minireference.com/blog/fixing-the-introductory-statistics-curriculum/">blog post</a> about the <em>modern statistics</em> curriculum). <strong>The main advantage so resampling methods is that they require less modelling assumptions.</strong> Procedures like the permutation test can be applied broadly to any scenario where two groups are being compared, and don’t require developing specific formulas for different cases. Resampling methods are easier to understand since the they are directly related to the sampling distribution, and there are no formulas to memorize.</p>
<p>Understanding resampling methods requires some basic familiarity with programming, but the skills required are not advanced: knowledge of variables, expressions, and basic <code class="docutils literal notranslate"><span class="pre">for</span></code> loop is sufficient. If you were able to follow the code examples described above (see <code class="docutils literal notranslate"><span class="pre">resample_under_H0</span></code>, <code class="docutils literal notranslate"><span class="pre">permutation_test</span></code>, and <code class="docutils literal notranslate"><span class="pre">bootstrap_stat</span></code>), then you’ve already <strong>seen all the code you will need for the entire book!</strong>  I’ve prepared a <a class="reference external" href="https://nobsstats.com/tutorials/python_tutorial.html">python tutorial</a> to make readers with no prior experience with Python will be able to quickly pick up the syntax.</p>
</section>
<section id="other-statistics-topics-in-the-book">
<h2>Other statistics topics in the book<a class="headerlink" href="#other-statistics-topics-in-the-book" title="Link to this heading">#</a></h2>
<p>The goal of this notebook was to focus on the two main ideas of inferential statistics (<a class="reference external" href="https://docs.google.com/document/d/1fwep23-95U-w1QMPU31nOvUnUXE2X3s_Dbk5JuLlKAY/edit#heading=h.uutryzqeo2av">Chapter 3</a>): hypothesis testing and estimation. We didn’t have time to cover many of the other important topics, which will be covered in the book (and in future <a class="reference external" href="https://nobsstats.com/notebooks/README.html">notebooks</a>). Here is a list of some of these topics:</p>
<ul class="simple">
<li><p>Null Hypothesis Significance Testing (NHST) procedure in full details (Type I and Type II error, power, sample size calculations)</p></li>
<li><p>Statistical assumptions behind analytical approximations</p></li>
<li><p>Inventory of statistical testing recipes (analytical approximations for different scenarios)</p></li>
<li><p>Experimental design (how to plan and conduct statistical experiments)</p></li>
<li><p>Misuses of statistics (caveats to watch out for, and mistakes to avoid)</p></li>
<li><p>Bayesian statistics (very deep topic; we’ll cover only main ideas)</p></li>
<li><p>Practice problems and exercises (real knowledge is when you can do the calculations yourself)</p></li>
</ul>
<hr class="docutils" />
<p>So far our statistical analysis was limited to comparing two groups, which is referred to as <strong>categorical predictor variable</strong> in stats jargon.
In the next notebook, we’ll learn about statistical analysis with <strong>continuous predictor variables</strong>: instead of comparing stats vs. no-stats, we analyze what happens when variable amount of stats training is provided (a continuous predictor variable).</p>
<p>Open the notebook <a class="reference internal" href="04_LINEAR_MODELS.html"><span class="std std-doc">04_LINEAR_MODELS.ipynb</span></a> when you’re ready to continue.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "minireference/noBSstats",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./stats_overview"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#notebook-setup">Notebook setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimators">Estimators</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#definitions">Definitions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#difference-between-group-means">Difference between group means</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#particular-value-of-the-estimator-dmeans">Particular value of the estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-distribution-of-the-estimator-dmeans">Sampling distribution of the estimator <code class="docutils literal notranslate"><span class="pre">dmeans</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-sampling-distribution-of-dmeans">Plot the sampling distribution of <code class="docutils literal notranslate"><span class="pre">dmeans</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#theoretical-model-for-the-sampling-distribution-of-dmeans">Theoretical model for the sampling distribution of <code class="docutils literal notranslate"><span class="pre">dmeans</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regroup-and-reality-check">Regroup and reality check</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#why-are-we-doing-all-this-modelling">Why are we doing all this modelling?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hypothesis-testing">Hypothesis testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview-of-the-hypothesis-testing-procedure">Overview of the hypothesis testing procedure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-the-result-of-a-hypothesis-test-optional">Interpreting the result of a hypothesis test (optional)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#start-by-loading-the-data-again">Start by loading the data again…</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-1-permutation-test-for-comparing-two-groups">Approach 1: Permutation test for comparing two groups</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#running-a-permutation-test">Running a permutation test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#permutations-test-using-scipy">Permutations test using SciPy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-2-analytical-approximations-for-hypothesis-testing">Approach 2: Analytical approximations for hypothesis testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#student-s-t-test-pooled-variance">Student’s t-test (pooled variance)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#black-box-approach">Black-box approach</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#student-s-t-test-under-the-hood">Student’s t-test under the hood</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#welch-s-t-test-unpooled-variances">Welch’s t-test (unpooled variances)</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-question-1">Summary of Question 1</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-the-effect-size">Estimating the effect size</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-1-confidence-intervals-using-bootstrap-estimation">Approach 1: Confidence intervals using bootstrap estimation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#scipy-bootstrap-method">SciPy bootstrap method</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approach-2-confidence-intervals-using-analytical-approximations">Approach 2: Confidence intervals using analytical approximations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pooled-variance">Using pooled variance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#using-unpooled-variance">Using unpooled variance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-question-2-results">Summary of Question 2 results</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#standardized-effect-size-optional">Standardized effect size (optional)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-of-amy-s-statistical-analysis">Conclusion of Amy’s statistical analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-statistics-for-convincing-others">Using statistics for convincing others</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-of-resampling-methods-and-analytical-approximations">Comparison of resampling methods and analytical approximations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-statistics-topics-in-the-book">Other statistics topics in the book</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ivan Savov
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>