{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83afb31c-0b3e-4b53-a83e-02d08b2d0969",
   "metadata": {},
   "source": [
    "## PyMC Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e47b054-f897-48fc-8dff-9cfe8538981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Ensure required Python modules are installed\n",
    "%pip install --quiet --upgrade numpy==2.3.5 bambi==0.16.0 pymc==5.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ebf988-f3c9-48a7-bb05-454d0381ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb099473-8e98-41fb-833b-a6a98f812671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Bambi v0.16.0\n",
      "Running on PyMC v5.26.1\n",
      "Running on PyTensor v2.35.1\n",
      "Running NymPy v2.3.5\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import pytensor\n",
    "import bambi as bmb\n",
    "\n",
    "print(f\"Running Bambi v{bmb.__version__}\")\n",
    "print(f\"Running on PyMC v{pm.__version__}\")\n",
    "print(f\"Running on PyTensor v{pytensor.__version__}\")\n",
    "print(f\"Running NymPy v{np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a243b61-ad98-4f3d-94a4-562020163191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('darwin',\n",
       " '3.12.4 (v3.12.4:8e8a4baf65, Jun  6 2024, 17:33:18) [Clang 13.0.0 (clang-1300.0.29.30)]')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.platform, sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f60369-9bdd-457d-a1c4-b21c48c53d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c3e5e5-331b-4369-b80c-21272829b7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "285c2ffb-ac90-4592-afe3-262402c3b460",
   "metadata": {},
   "source": [
    "## Example: complete pooling model on Radon dataset\n",
    "\n",
    "= common linear regression model for all counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8415f314-b97b-457e-9631-976a29f31e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(919, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radon = pd.read_csv(\"https://raw.githubusercontent.com/minireference/noBSstats/refs/heads/main/datasets/radon.csv\")\n",
    "radon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c4778f-63ac-4236-9d09-27194ab17b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idnum</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>floor</th>\n",
       "      <th>log_radon</th>\n",
       "      <th>log_uranium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5081</td>\n",
       "      <td>MN</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>ground</td>\n",
       "      <td>0.788457</td>\n",
       "      <td>-0.689048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5082</td>\n",
       "      <td>MN</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>basement</td>\n",
       "      <td>0.788457</td>\n",
       "      <td>-0.689048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5083</td>\n",
       "      <td>MN</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>basement</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>-0.689048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5084</td>\n",
       "      <td>MN</td>\n",
       "      <td>AITKIN</td>\n",
       "      <td>basement</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.689048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5085</td>\n",
       "      <td>MN</td>\n",
       "      <td>ANOKA</td>\n",
       "      <td>basement</td>\n",
       "      <td>1.131402</td>\n",
       "      <td>-0.847313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idnum state  county     floor  log_radon  log_uranium\n",
       "0   5081    MN  AITKIN    ground   0.788457    -0.689048\n",
       "1   5082    MN  AITKIN  basement   0.788457    -0.689048\n",
       "2   5083    MN  AITKIN  basement   1.064711    -0.689048\n",
       "3   5084    MN  AITKIN  basement   0.000000    -0.689048\n",
       "4   5085    MN   ANOKA  basement   1.131402    -0.847313"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4393248-626d-4870-9937-65950cb581ff",
   "metadata": {},
   "source": [
    "### Bayesian model\n",
    "\n",
    "\n",
    "We can  pool all the data and estimate one big regression to asses the influence of the floor variable\n",
    "on radon levels across all counties.\n",
    "\n",
    "\\begin{align*}\n",
    "    R\t\t\t&\\sim\t\\calN(M_R, \\, \\Sigma_R),  \t\\\\\n",
    "    M_R\t\t\t&=\t\tB_0 + B_{\\!f}\\!\\cdot\\!f,\t\\\\\n",
    "    \\Sigma_R\t&\\sim\t\\Tdist^+\\!(4, 1),\t\t\t\\\\\n",
    "    B_0\t\t\t&\\sim\t\\calN(1, 2), \t\t\t\t\\\\\n",
    "    B_f\t\t\t&\\sim\t\\calN(0, 5).\n",
    "\\end{align*}\n",
    "\n",
    "The variable $f$ corresponds to the column `floor` in the `radon` data frame,\n",
    "which will be internally coded as binary\n",
    "with $0$ representing basement,\n",
    "and $1$ representing ground floor.\n",
    "\n",
    "By ignoring the county feature, we do not differenciate on counties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88a8b14-c810-4083-acfb-3dbd5b69f5c3",
   "metadata": {},
   "source": [
    "### Bambi model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982d2638-9254-4d14-9d9d-f969725f165b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Formula: log_radon ~ 1 + floor\n",
       "        Family: gaussian\n",
       "          Link: mu = identity\n",
       "  Observations: 919\n",
       "        Priors: \n",
       "    target = mu\n",
       "        Common-level effects\n",
       "            Intercept ~ Normal(mu: 1.0, sigma: 2.0)\n",
       "            floor ~ Normal(mu: 0.0, sigma: 5.0)\n",
       "        \n",
       "        Auxiliary parameters\n",
       "            sigma ~ HalfStudentT(nu: 4.0, sigma: 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bambi as bmb\n",
    "\n",
    "priors1 = {\n",
    "    \"Intercept\": bmb.Prior(\"Normal\", mu=1, sigma=2),\n",
    "    \"floor\": bmb.Prior(\"Normal\", mu=0, sigma=5),\n",
    "    \"sigma\": bmb.Prior(\"HalfStudentT\", nu=4, sigma=1),\n",
    "}\n",
    "\n",
    "mod1 = bmb.Model(formula=\"log_radon ~ 1 + floor\",\n",
    "                 family=\"gaussian\",\n",
    "                 link=\"identity\",\n",
    "                 priors=priors1,\n",
    "                 data=radon)\n",
    "mod1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacbbfa0-59c2-4a39-9a96-b4df4b726a11",
   "metadata": {},
   "source": [
    "### Model fitting and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6994c1e3-1f05-4536-930d-8a8093fe2bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, Intercept, floor]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e61235fead409eb8c9479fa6915e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process worker_chain_0:\n",
      "Process worker_chain_1:\n",
      "Process worker_chain_2:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process worker_chain_3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 153, in run\n",
      "    self._start_loop()\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 153, in run\n",
      "    self._start_loop()\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 153, in run\n",
      "    self._start_loop()\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 210, in _start_loop\n",
      "    point, stats = self._step_method.step(self._point)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 210, in _start_loop\n",
      "    point, stats = self._step_method.step(self._point)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 210, in _start_loop\n",
      "    point, stats = self._step_method.step(self._point)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/arraystep.py\", line 116, in step\n",
      "    apoint, stats = self.astep(q)\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/arraystep.py\", line 116, in step\n",
      "    apoint, stats = self.astep(q)\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/arraystep.py\", line 116, in step\n",
      "    apoint, stats = self.astep(q)\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 153, in run\n",
      "    self._start_loop()\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/base_hmc.py\", line 233, in astep\n",
      "    hmc_step = self._hamiltonian_step(start, p0, step_size)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/base_hmc.py\", line 233, in astep\n",
      "    hmc_step = self._hamiltonian_step(start, p0, step_size)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/base_hmc.py\", line 233, in astep\n",
      "    hmc_step = self._hamiltonian_step(start, p0, step_size)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 210, in _start_loop\n",
      "    point, stats = self._step_method.step(self._point)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 217, in _hamiltonian_step\n",
      "    divergence_info, turning = tree.extend(direction)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 217, in _hamiltonian_step\n",
      "    divergence_info, turning = tree.extend(direction)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 217, in _hamiltonian_step\n",
      "    divergence_info, turning = tree.extend(direction)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/arraystep.py\", line 116, in step\n",
      "    apoint, stats = self.astep(q)\n",
      "                    ^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 348, in extend\n",
      "    tree, diverging, turning = self._build_subtree(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 357, in extend\n",
      "    tree, diverging, turning = self._build_subtree(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/base_hmc.py\", line 233, in astep\n",
      "    hmc_step = self._hamiltonian_step(start, p0, step_size)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 357, in extend\n",
      "    tree, diverging, turning = self._build_subtree(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 445, in _build_subtree\n",
      "    return self._single_step(left, epsilon)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 217, in _hamiltonian_step\n",
      "    divergence_info, turning = tree.extend(direction)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 445, in _build_subtree\n",
      "    return self._single_step(left, epsilon)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 445, in _build_subtree\n",
      "    return self._single_step(left, epsilon)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 401, in _single_step\n",
      "    right = self.integrator.step(epsilon, left)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 357, in extend\n",
      "    tree, diverging, turning = self._build_subtree(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 401, in _single_step\n",
      "    right = self.integrator.step(epsilon, left)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 401, in _single_step\n",
      "    right = self.integrator.step(epsilon, left)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/integration.py\", line 94, in step\n",
      "    return self._step(epsilon, state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 445, in _build_subtree\n",
      "    return self._single_step(left, epsilon)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/integration.py\", line 94, in step\n",
      "    return self._step(epsilon, state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/integration.py\", line 94, in step\n",
      "    return self._step(epsilon, state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/integration.py\", line 120, in _step\n",
      "    axpy(state.q_grad, p_new, a=dt)\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/integration.py\", line 120, in _step\n",
      "    axpy(state.q_grad, p_new, a=dt)\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/integration.py\", line 120, in _step\n",
      "    axpy(state.q_grad, p_new, a=dt)\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/nuts.py\", line 401, in _single_step\n",
      "    right = self.integrator.step(epsilon, left)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_fblas.error: (len(y)-offy>(n-1)*abs(incy)) failed for 1st keyword n: daxpy:n=921\n",
      "_fblas.error: (len(y)-offy>(n-1)*abs(incy)) failed for 1st keyword n: daxpy:n=921\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/integration.py\", line 94, in step\n",
      "    return self._step(epsilon, state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "_fblas.error: (len(y)-offy>(n-1)*abs(incy)) failed for 1st keyword n: daxpy:n=921\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/step_methods/hmc/integration.py\", line 120, in _step\n",
      "    axpy(state.q_grad, p_new, a=dt)\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "_fblas.error: (len(y)-offy>(n-1)*abs(incy)) failed for 1st keyword n: daxpy:n=921\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 232, in _run_process\n",
      "    _Process(*args).run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 232, in _run_process\n",
      "    _Process(*args).run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 160, in run\n",
      "    self._msg_pipe.send((\"error\", e))\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 232, in _run_process\n",
      "    _Process(*args).run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 160, in run\n",
      "    self._msg_pipe.send((\"error\", e))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 160, in run\n",
      "    self._msg_pipe.send((\"error\", e))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_pickle.PicklingError: Can't pickle <class '_fblas.error'>: import of module '_fblas' failed\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 232, in _run_process\n",
      "    _Process(*args).run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "  File \"/Users/ivan/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py\", line 160, in run\n",
      "    self._msg_pipe.send((\"error\", e))\n",
      "_pickle.PicklingError: Can't pickle <class '_fblas.error'>: import of module '_fblas' failed\n",
      "_pickle.PicklingError: Can't pickle <class '_fblas.error'>: import of module '_fblas' failed\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 206, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "_pickle.PicklingError: Can't pickle <class '_fblas.error'>: import of module '_fblas' failed\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEOFError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m idata1 = \u001b[43mmod1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/bambi/models.py:345\u001b[39m, in \u001b[36mModel.fit\u001b[39m\u001b[34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_mean, include_response_params, inference_method, init, n_init, chains, cores, random_seed, **kwargs)\u001b[39m\n\u001b[32m    338\u001b[39m     warnings.warn(\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33minclude_mean\u001b[39m\u001b[33m'\u001b[39m\u001b[33m has been replaced by \u001b[39m\u001b[33m'\u001b[39m\u001b[33minclude_response_params\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mis not going to work in the future\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    341\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    342\u001b[39m     )\n\u001b[32m    343\u001b[39m     include_response_params = include_mean\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43momit_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43momit_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_response_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_response_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43minference_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcores\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/bambi/backend/pymc.py:155\u001b[39m, in \u001b[36mPyMCModel.run\u001b[39m\u001b[34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_response_params, inference_method, init, n_init, chains, cores, random_seed, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._run_laplace(\n\u001b[32m    150\u001b[39m         draws=draws,\n\u001b[32m    151\u001b[39m         omit_offsets=omit_offsets,\n\u001b[32m    152\u001b[39m         include_response_params=include_response_params,\n\u001b[32m    153\u001b[39m     )\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_mcmc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43momit_offsets\u001b[49m\u001b[43m=\u001b[49m\u001b[43momit_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_response_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_response_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcores\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43msampler_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;28mself\u001b[39m.fit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/bambi/backend/pymc.py:226\u001b[39m, in \u001b[36mPyMCModel._run_mcmc\u001b[39m\u001b[34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_response_params, init, n_init, chains, cores, random_seed, sampler_backend, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model:\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m         idata = \u001b[43mpm\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m            \u001b[49m\u001b[43minit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcores\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvar_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvars_to_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnuts_sampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampler_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mRuntimeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m    240\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mValueError: Mass matrix contains\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m traceback.format_exc() \u001b[38;5;129;01mand\u001b[39;00m init == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/mcmc.py:928\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, compile_kwargs, **kwargs)\u001b[39m\n\u001b[32m    926\u001b[39m _print_step_hierarchy(step)\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m     \u001b[43m_mp_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msample_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparallel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m pickle.PickleError:\n\u001b[32m    930\u001b[39m     _log.warning(\u001b[33m\"\u001b[39m\u001b[33mCould not pickle model, sampling singlethreaded.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/mcmc.py:1404\u001b[39m, in \u001b[36m_mp_sample\u001b[39m\u001b[34m(draws, tune, step, chains, cores, rngs, start, progressbar, progressbar_theme, traces, model, callback, blas_cores, mp_ctx, **kwargs)\u001b[39m\n\u001b[32m   1402\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1403\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m sampler:\n\u001b[32m-> \u001b[39m\u001b[32m1404\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstrace\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mzarr_recording\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Zarr recording happens in each process\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py:509\u001b[39m, in \u001b[36mParallelSampler.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._progress:\n\u001b[32m    508\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._active:\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m         draw = \u001b[43mProcessAdapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_draw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_active\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m         proc, is_last, draw, tuning, stats = draw\n\u001b[32m    512\u001b[39m         \u001b[38;5;28mself\u001b[39m._progress.update(\n\u001b[32m    513\u001b[39m             chain_idx=proc.chain, is_last=is_last, draw=draw, tuning=tuning, stats=stats\n\u001b[32m    514\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Minireference/STATSbook/noBSstats/venv/lib/python3.12/site-packages/pymc/sampling/parallel.py:370\u001b[39m, in \u001b[36mProcessAdapter.recv_draw\u001b[39m\u001b[34m(processes, timeout)\u001b[39m\n\u001b[32m    368\u001b[39m idxs = {\u001b[38;5;28mid\u001b[39m(proc._msg_pipe): proc \u001b[38;5;28;01mfor\u001b[39;00m proc \u001b[38;5;129;01min\u001b[39;00m processes}\n\u001b[32m    369\u001b[39m proc = idxs[\u001b[38;5;28mid\u001b[39m(ready[\u001b[32m0\u001b[39m])]\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m msg = \u001b[43mready\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m msg[\u001b[32m0\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    373\u001b[39m     old_error = msg[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py:250\u001b[39m, in \u001b[36m_ConnectionBase.recv\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    249\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler.loads(buf.getbuffer())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py:430\u001b[39m, in \u001b[36mConnection._recv_bytes\u001b[39m\u001b[34m(self, maxsize)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     size, = struct.unpack(\u001b[33m\"\u001b[39m\u001b[33m!i\u001b[39m\u001b[33m\"\u001b[39m, buf.getvalue())\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m size == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py:399\u001b[39m, in \u001b[36mConnection._recv\u001b[39m\u001b[34m(self, size, read)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m remaining == size:\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgot end of file during message\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mEOFError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "idata1 = mod1.fit(random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b352b-49df-4a02-bed7-c8571dc1989b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f3046a-42fb-48f8-9d61-03f707a055f5",
   "metadata": {},
   "source": [
    "## Example 2: no pooling model\n",
    "\n",
    "= separate intercept for each county "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37102cc-20fe-44b4-b5f3-4b49f9a9ee6f",
   "metadata": {},
   "source": [
    "### Bayesian model\n",
    "\n",
    "If we treat different counties as independent,\n",
    "so each one gets an intercept term:\n",
    "\n",
    "\\begin{align*}\n",
    "    R_j\t\t\t&\\sim\t\\calN(M_j, \\, \\Sigma_R),  \t\t\t\t\t\\\\\n",
    "    M_j\t\t\t&=\t\tB_{0j} + B_{\\!f}\\!\\cdot\\!f,\t\t\t\t\t\\\\\n",
    "    \\Sigma_R\t\t&\\sim\t\\Tdist^+\\!(4, 1),\t\t\t\t\t\t\t\\\\\n",
    "    B_{0j}\t\t&\\sim\t\\calN(1, 2),\t\t\t\t\t\t\t\\\\\n",
    "    B_f\t\t\t&\\sim\t\\calN(0, 5).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55d76c-27c5-4904-a841-b6a67df1ffd9",
   "metadata": {},
   "source": [
    "### Bambi model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170bd5a2-ada6-49a9-b93e-8cb4ab204955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Formula: log_radon ~ 0 + county + floor\n",
       "        Family: gaussian\n",
       "          Link: mu = identity\n",
       "  Observations: 919\n",
       "        Priors: \n",
       "    target = mu\n",
       "        Common-level effects\n",
       "            county ~ Normal(mu: 1.0, sigma: 2.0)\n",
       "            floor ~ Normal(mu: 0.0, sigma: 5.0)\n",
       "        \n",
       "        Auxiliary parameters\n",
       "            sigma ~ HalfStudentT(nu: 4.0, sigma: 1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors2 = {\n",
    "    \"county\": bmb.Prior(\"Normal\", mu=1, sigma=2),\n",
    "    \"floor\": bmb.Prior(\"Normal\", mu=0, sigma=5),\n",
    "    \"sigma\": bmb.Prior(\"HalfStudentT\", nu=4, sigma=1),\n",
    "}\n",
    "\n",
    "mod2 = bmb.Model(\"log_radon ~ 0 + county + floor\",\n",
    "                 family=\"gaussian\",\n",
    "                 link=\"identity\",\n",
    "                 priors=priors2,\n",
    "                 data=radon)\n",
    "mod2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74bcd6b-2467-4a81-aad0-e7480bc28ab3",
   "metadata": {},
   "source": [
    "### Model fitting and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360e736c-3be0-41a9-8e66-c6cd4202095c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma, county, floor]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d54f51f62dc49f9a7140a2af0aa16dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.\n"
     ]
    }
   ],
   "source": [
    "idata2 = mod2.fit(random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3348bed9-fe59-48d5-a9bd-c4f844dbb310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
