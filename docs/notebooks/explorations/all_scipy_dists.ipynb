{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e48cd4-b217-41ab-97d9-e9c9690153e9",
   "metadata": {},
   "source": [
    "## Visualizing scipy.stats distributions\n",
    "\n",
    "What do all the distributions available in scipy.stats look like?\n",
    "\n",
    "This [answer](https://stackoverflow.com/a/37559471/127114) on stackoverflow shows them all!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14fc7b2-efe0-44d4-b266-aaf13c7f1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import io, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 14.0)\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "936bb06c-ba4d-498b-80e8-269135432656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions to check, shape constants were taken from the examples on the scipy.stats distribution documentation pages.\n",
    "DISTRIBUTIONS = [\n",
    "    stats.alpha(a=3.57, loc=0.0, scale=1.0), stats.anglit(loc=0.0, scale=1.0), \n",
    "    stats.arcsine(loc=0.0, scale=1.0), stats.beta(a=2.31, b=0.627, loc=0.0, scale=1.0), \n",
    "    stats.betaprime(a=5, b=6, loc=0.0, scale=1.0), stats.bradford(c=0.299, loc=0.0, scale=1.0),\n",
    "    stats.burr(c=10.5, d=4.3, loc=0.0, scale=1.0), stats.cauchy(loc=0.0, scale=1.0), \n",
    "    stats.chi(df=78, loc=0.0, scale=1.0), stats.chi2(df=55, loc=0.0, scale=1.0),\n",
    "    stats.cosine(loc=0.0, scale=1.0), stats.dgamma(a=1.1, loc=0.0, scale=1.0), \n",
    "    stats.dweibull(c=2.07, loc=0.0, scale=1.0), stats.erlang(a=2, loc=0.0, scale=1.0), \n",
    "    stats.expon(loc=0.0, scale=1.0), stats.exponnorm(K=1.5, loc=0.0, scale=1.0),\n",
    "    stats.exponweib(a=2.89, c=1.95, loc=0.0, scale=1.0), stats.exponpow(b=2.7, loc=0.0, scale=1.0),\n",
    "    stats.f(dfn=29, dfd=18, loc=0.0, scale=1.0), stats.fatiguelife(c=29, loc=0.0, scale=1.0), \n",
    "    stats.fisk(c=3.09, loc=0.0, scale=1.0), stats.foldcauchy(c=4.72, loc=0.0, scale=1.0),\n",
    "    # stats.foldnorm(c=1.95, loc=0.0, scale=1.0), stats.frechet_r(c=1.89, loc=0.0, scale=1.0),\n",
    "    # stats.frechet_l(c=3.63, loc=0.0, scale=1.0), stats.genlogistic(c=0.412, loc=0.0, scale=1.0),\n",
    "    stats.genpareto(c=0.1, loc=0.0, scale=1.0), stats.gennorm(beta=1.3, loc=0.0, scale=1.0), \n",
    "    stats.genexpon(a=9.13, b=16.2, c=3.28, loc=0.0, scale=1.0), stats.genextreme(c=-0.1, loc=0.0, scale=1.0),\n",
    "    stats.gausshyper(a=13.8, b=3.12, c=2.51, z=5.18, loc=0.0, scale=1.0), stats.gamma(a=1.99, loc=0.0, scale=1.0),\n",
    "    stats.gengamma(a=4.42, c=-3.12, loc=0.0, scale=1.0), stats.genhalflogistic(c=0.773, loc=0.0, scale=1.0),\n",
    "    stats.gilbrat(loc=0.0, scale=1.0), stats.gompertz(c=0.947, loc=0.0, scale=1.0),\n",
    "    stats.gumbel_r(loc=0.0, scale=1.0), stats.gumbel_l(loc=0.0, scale=1.0),\n",
    "    stats.halfcauchy(loc=0.0, scale=1.0), stats.halflogistic(loc=0.0, scale=1.0),\n",
    "    stats.halfnorm(loc=0.0, scale=1.0), stats.halfgennorm(beta=0.675, loc=0.0, scale=1.0),\n",
    "    stats.hypsecant(loc=0.0, scale=1.0), stats.invgamma(a=4.07, loc=0.0, scale=1.0),\n",
    "    stats.invgauss(mu=0.145, loc=0.0, scale=1.0), stats.invweibull(c=10.6, loc=0.0, scale=1.0),\n",
    "    stats.johnsonsb(a=4.32, b=3.18, loc=0.0, scale=1.0), stats.johnsonsu(a=2.55, b=2.25, loc=0.0, scale=1.0),\n",
    "    stats.ksone(n=1e+03, loc=0.0, scale=1.0), stats.kstwobign(loc=0.0, scale=1.0),\n",
    "    stats.laplace(loc=0.0, scale=1.0), stats.levy(loc=0.0, scale=1.0),\n",
    "    stats.levy_l(loc=0.0, scale=1.0), stats.levy_stable(alpha=0.357, beta=-0.675, loc=0.0, scale=1.0),\n",
    "    stats.logistic(loc=0.0, scale=1.0), stats.loggamma(c=0.414, loc=0.0, scale=1.0),\n",
    "    stats.loglaplace(c=3.25, loc=0.0, scale=1.0), stats.lognorm(s=0.954, loc=0.0, scale=1.0),\n",
    "    stats.lomax(c=1.88, loc=0.0, scale=1.0), stats.maxwell(loc=0.0, scale=1.0),\n",
    "    stats.mielke(k=10.4, s=3.6, loc=0.0, scale=1.0), stats.nakagami(nu=4.97, loc=0.0, scale=1.0),\n",
    "    stats.ncx2(df=21, nc=1.06, loc=0.0, scale=1.0), stats.ncf(dfn=27, dfd=27, nc=0.416, loc=0.0, scale=1.0),\n",
    "    stats.nct(df=14, nc=0.24, loc=0.0, scale=1.0), stats.norm(loc=0.0, scale=1.0),\n",
    "    stats.pareto(b=2.62, loc=0.0, scale=1.0), stats.pearson3(skew=0.1, loc=0.0, scale=1.0),\n",
    "    stats.powerlaw(a=1.66, loc=0.0, scale=1.0), stats.powerlognorm(c=2.14, s=0.446, loc=0.0, scale=1.0),\n",
    "    stats.powernorm(c=4.45, loc=0.0, scale=1.0), stats.rdist(c=0.9, loc=0.0, scale=1.0),\n",
    "    stats.reciprocal(a=0.00623, b=1.01, loc=0.0, scale=1.0), stats.rayleigh(loc=0.0, scale=1.0),\n",
    "    stats.rice(b=0.775, loc=0.0, scale=1.0), stats.recipinvgauss(mu=0.63, loc=0.0, scale=1.0),\n",
    "    stats.semicircular(loc=0.0, scale=1.0), stats.t(df=2.74, loc=0.0, scale=1.0),\n",
    "    stats.triang(c=0.158, loc=0.0, scale=1.0), stats.truncexpon(b=4.69, loc=0.0, scale=1.0),\n",
    "    stats.truncnorm(a=0.1, b=2, loc=0.0, scale=1.0), stats.tukeylambda(lam=3.13, loc=0.0, scale=1.0),\n",
    "    stats.uniform(loc=0.0, scale=1.0), stats.vonmises(kappa=3.99, loc=0.0, scale=1.0),\n",
    "    stats.vonmises_line(kappa=3.99, loc=0.0, scale=1.0), stats.wald(loc=0.0, scale=1.0),\n",
    "    stats.weibull_min(c=1.79, loc=0.0, scale=1.0), stats.weibull_max(c=2.87, loc=0.0, scale=1.0),\n",
    "    stats.wrapcauchy(c=0.0311, loc=0.0, scale=1.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ce6796-55f9-492a-ab90-001a02c97eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/2r44j8gs4gn56t1xtw5f6wlm0000gn/T/ipykernel_35683/1332613993.py:19: VisibleDeprecationWarning: Passing `normed=True` on non-uniform bins has always been broken, and computes neither the probability density function nor the probability mass function. The result is only correct if the bins are uniform, when density=True will produce the same result anyway. The argument will be removed in a future version of numpy.\n",
      "  y, x = np.histogram(rv, bins=b, normed=True)\n"
     ]
    }
   ],
   "source": [
    "bins = 32\n",
    "size = 16384\n",
    "plotData = []\n",
    "for distribution in DISTRIBUTIONS:\n",
    "    try:  \n",
    "        # Create random data\n",
    "        rv = pd.Series(distribution.rvs(size=size))\n",
    "        # Get sane start and end points of distribution\n",
    "        start = distribution.ppf(0.01)\n",
    "        end = distribution.ppf(0.99)\n",
    "\n",
    "        # Build PDF and turn into pandas Series\n",
    "        x = np.linspace(start, end, size)\n",
    "        y = distribution.pdf(x)\n",
    "        pdf = pd.Series(y, x)\n",
    "\n",
    "        # Get histogram of random data\n",
    "        b = np.linspace(start, end, bins+1)\n",
    "        y, x = np.histogram(rv, bins=b, normed=True)\n",
    "        x = [(a+x[i+1])/2.0 for i,a in enumerate(x[0:-1])]\n",
    "        hist = pd.Series(y, x)\n",
    "\n",
    "        # Create distribution name and parameter string\n",
    "        title = '{}({})'.format(distribution.dist.name, ', '.join(['{}={:0.2f}'.format(k,v) for k,v in distribution.kwds.items()]))\n",
    "\n",
    "        # Store data for later\n",
    "        plotData.append({\n",
    "            'pdf': pdf,\n",
    "            'hist': hist,\n",
    "            'title': title\n",
    "        })\n",
    "\n",
    "    except Exception:\n",
    "        print('could not create data', distribution.dist.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b7233e-ef1b-46f7-b337-4a2cd9039b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('all_scipy_dists', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fe691c9-39fd-42e0-9e14-d1122eecaf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMax = len(plotData)\n",
    "\n",
    "for i, data in enumerate(plotData):\n",
    "    w = abs(abs(data['hist'].index[0]) - abs(data['hist'].index[1]))\n",
    "\n",
    "    # Display\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ax = data['pdf'].plot(kind='line', label='Model PDF', legend=True, lw=2)\n",
    "    ax.bar(data['hist'].index, data['hist'].values, label='Random Sample', width=w, align='center', alpha=0.5)\n",
    "    ax.set_title(data['title'])\n",
    "\n",
    "    # Grab figure\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    # Output 'file'\n",
    "    outfile = os.path.join('all_scipy_dists', data['title'] + '.png')\n",
    "    fig.savefig(outfile, format='png', bbox_inches='tight')\n",
    "    matplotlib.pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ab9ef-beab-4dcd-8182-3c183a135540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b7edd4-c486-461a-8a84-4671a5cd29fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3af1f7-0bcf-4896-82f5-9716e538a5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d23c4b48-d226-4649-bb6e-c81d9376c982",
   "metadata": {},
   "source": [
    "### Alternative version\n",
    "\n",
    "via https://stackoverflow.com/a/65957876/127114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa281bf-3628-4c13-b4d2-c2aea944ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np         # v 1.19.2\n",
    "# from scipy import stats    # v 1.5.2\n",
    "# import pandas as pd        # v 1.1.3\n",
    "\n",
    "# pd.options.display.max_columns = 6\n",
    "# np.random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abab1290-159c-43bd-a5af-d49ec9dd81ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = 10000\n",
    "# names, xlabels, frozen_rvs, samples = [], [], [], []\n",
    "\n",
    "# # Extract names and sane parameters of all scipy probability distributions\n",
    "# # (except the deprecated ones) and loop through them to create lists of names,\n",
    "# # frozen random variables, samples of random variates and x labels\n",
    "# for name, params in stats._distr_params.distcont:\n",
    "#     if name not in ['frechet_l', 'frechet_r']:\n",
    "#         loc, scale = 0, 1\n",
    "#         names.append(name)\n",
    "#         params = list(params) + [loc, scale]\n",
    "        \n",
    "#         # Create instance of random variable\n",
    "#         dist = getattr(stats, name)\n",
    "        \n",
    "#         # Create frozen random variable using parameters and add it to the list\n",
    "#         # to be used to draw the probability density functions\n",
    "#         rv = dist(*params)\n",
    "#         frozen_rvs.append(rv)\n",
    "        \n",
    "#         # Create sample of random variates\n",
    "#         samples.append(rv.rvs(size=size))\n",
    "        \n",
    "#         # Create x label containing the distribution parameters\n",
    "#         p_names = ['loc', 'scale']\n",
    "#         if dist.shapes:\n",
    "#             p_names = [sh.strip() for sh in dist.shapes.split(',')] + ['loc', 'scale']\n",
    "#         xlabels.append(', '.join([f'{pn}={pv:.2f}' for pn, pv in zip(p_names, params)]))\n",
    "\n",
    "# # Create pandas dataframe containing all the samples\n",
    "# df = pd.DataFrame(data=np.array(samples).T, columns=[name for name in names])\n",
    "# # Rename the duplicate column names by adding a period and an integer at the end\n",
    "# df.columns = pd.io.parsers.ParserBase({'names':df.columns})._maybe_dedup_names(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9df786-5077-46e9-aca0-e53f3635b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set parameters for figure dimensions\n",
    "# nplot = df.columns.size\n",
    "# cols = 3\n",
    "# rows = int(np.ceil(nplot/cols))\n",
    "# subp_w = 10/cols  # 10 corresponds to the figure width in inches\n",
    "# subp_h = 0.9*subp_w\n",
    "\n",
    "# # Create pandas grid of histograms\n",
    "# axs = df.hist(density=True, bins=15, grid=False, edgecolor='w',\n",
    "#               linewidth=0.5, legend=False,\n",
    "#               layout=(rows, cols), figsize=(cols*subp_w, rows*subp_h))\n",
    "\n",
    "# # Loop over subplots to draw probability density function and apply some\n",
    "# # additional formatting\n",
    "# for idx, ax in enumerate(axs.flat[:df.columns.size]):\n",
    "#     rv = frozen_rvs[idx]\n",
    "#     x = np.linspace(rv.ppf(0.001), rv.ppf(0.999), size)\n",
    "#     ax.plot(x, rv.pdf(x), c='black', alpha=0.5)\n",
    "#     ax.set_title(ax.get_title(), pad=25)\n",
    "#     ax.set_xlim(x.min(), x.max())\n",
    "#     ax.set_xlabel(xlabels[idx], fontsize=8, labelpad=10)\n",
    "#     ax.xaxis.set_label_position('top')\n",
    "#     ax.tick_params(axis='both', labelsize=9)\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "\n",
    "# ax.figure.subplots_adjust(hspace=0.8, wspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91aea58-824d-4ed1-8213-b846ede341fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
